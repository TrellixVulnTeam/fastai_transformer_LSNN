{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from fastai import *        # Quick accesss to most common functionality\n",
    "from fastai.text import *   # Quick accesss to NLP functionality\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import OpenAIGPTTokenizer#, OpenAIGPTModel, OpenAIGPTLMHeadModel\n",
    "from gpt import OpenAIGPTModel, OpenAIGPTLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all(self, texts):\n",
    "    return [self.tokenize(x) for x in texts]\n",
    "\n",
    "# def numericalize(self, tokenized_text):\n",
    "#     return self.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# def textify(self, ids):\n",
    "#     return tokenizer.convert_ids_to_tokens\n",
    "\n",
    "OpenAIGPTTokenizer.process_all = process_all\n",
    "OpenAIGPTTokenizer.numericalize = OpenAIGPTTokenizer.convert_tokens_to_ids\n",
    "OpenAIGPTTokenizer.textify = OpenAIGPTTokenizer.convert_ids_to_tokens\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
    "\n",
    "# Tokenized input\n",
    "\n",
    "text = \"Who was Jim Henson ? Jim Henson was a puppeteer\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/wikitext-2-raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fn:PathOrStr, enc='utf-8'):\n",
    "    \"Read the text in `fn`.\"\n",
    "#     with open(fn,'r', encoding = enc) as f: return ''.join(f.read().splitlines())\n",
    "    tokens = []\n",
    "    with open(fn,'r', encoding = enc) as f: \n",
    "        for line in f.read().splitlines():\n",
    "            l = line.strip()\n",
    "            if len(l) == 0: continue\n",
    "            tokens.append(l)#.split())\n",
    "    return np.array(tokens)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = read_file(PATH/'wiki.train.raw')\n",
    "valid_tok = read_file(PATH/'wiki.valid.raw')\n",
    "test_tok = read_file(PATH/'wiki.test.raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTTokenizeProcessor(PreProcessor):\n",
    "    \"`PreProcessor` that tokenizes the texts in `ds`.\"\n",
    "    def __init__(self, ds:ItemList=None, tokenizer:Tokenizer=None, chunksize:int=10000):\n",
    "        self.tokenizer,self.chunksize = ifnone(tokenizer, Tokenizer()),chunksize\n",
    "\n",
    "    def process_one(self, item):  return self.tokenizer._process_all_1([item])[0]\n",
    "    def process(self, ds):\n",
    "#         ds.items = _join_texts(ds.items, self.mark_fields)\n",
    "        tokens = []\n",
    "        for i in progress_bar(range(0,len(ds),self.chunksize), leave=False):\n",
    "            tokens += self.tokenizer.process_all(ds.items[i:i+self.chunksize])\n",
    "        ds.items = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [GPTTokenizeProcessor(chunksize=1000, tokenizer=tokenizer), \n",
    "     NumericalizeProcessor(vocab=tokenizer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 128\n",
    "bs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH\n",
    "# processor = data._get_processor(tokenizer=tok, vocab=None, max_vocab=60000)\n",
    "# processor = data._get_processor(vocab=None, chunksize=500)\n",
    "src = ItemLists(path, TextList(train_tok, path=path, processor=p),\n",
    "                TextList(valid_tok, path=path, processor=p))\n",
    "src = src.label_for_lm()\n",
    "text_data = src.databunch(bs=bs,bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text ['sen', 'j', '≈ç</w>', 'no</w>', 'val', 'ky', 'ria</w>', '3</w>', ':</w>', 'un', 'recorded</w>', 'chronicles</w>', '(</w>', 'japanese</w>', ':</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '3</w>', ',</w>', 'lit</w>', '.</w>', 'val', 'ky', 'ria</w>', 'of</w>', 'the</w>', 'battlefield</w>', '3</w>', ')</w>', ',</w>', 'commonly</w>', 'referred</w>', 'to</w>', 'as</w>', 'val', 'ky', 'ria</w>', 'chronicles</w>', 'iii</w>', 'outside</w>', 'japan</w>', ',</w>', 'is</w>', 'a</w>', 'tactical</w>', 'role</w>', '@</w>', '-</w>', '@</w>', 'playing</w>', 'video</w>', 'game</w>', 'developed</w>', 'by</w>', 'se', 'ga</w>', 'and</w>', 'media</w>', '.</w>', 'vision</w>', 'for</w>', 'the</w>', 'play', 'station</w>', 'portable</w>', '.</w>', 'released</w>', 'in</w>', 'january</w>', '2011</w>', 'in</w>', 'japan</w>', ',</w>', 'it</w>', 'is</w>', 'the</w>', 'third</w>', 'game</w>', 'in</w>', 'the</w>', 'val', 'ky', 'ria</w>', 'series</w>', '.</w>', 'employing</w>', 'the</w>', 'same</w>', 'fusion</w>', 'of</w>', 'tactical</w>', 'and</w>', 'real</w>', '@</w>', '-</w>', '@</w>', 'time</w>', 'ga', 'me', 'play</w>', 'as</w>', 'its</w>', 'predecessors</w>', ',</w>', 'the</w>', 'story</w>', 'runs</w>', 'parallel</w>', 'to</w>', 'the</w>', 'first</w>', 'game</w>', 'and</w>', 'follows</w>', 'the</w>', '\"</w>', 'nameless</w>', '\"</w>', ',</w>', 'a</w>', 'pen', 'al</w>', 'military</w>', 'unit</w>', 'serving</w>', 'the</w>', 'nation</w>', 'of</w>', 'gal', 'lia</w>', 'during</w>', 'the</w>', 'second</w>', 'euro', 'pan</w>', 'war</w>', 'who</w>', 'perform</w>', 'secret</w>', 'black</w>', 'operations</w>', 'and</w>', 'are</w>', 'pitted</w>', 'against</w>', 'the</w>', 'imperial</w>', 'unit</w>', '\"</w>', 'cal', 'amat', 'y</w>', 'raven</w>', '\"</w>', '.</w>'],\n",
       " Category 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLoss():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    def forward(self, lm_logits, lm_labels):\n",
    "        loss = self.loss_fct(lm_logits.view(-1, lm_logits.size(-1)), lm_labels.view(-1))\n",
    "        return loss\n",
    "    def __call__(self, lm_logits, lm_labels):\n",
    "        loss = self.loss_fct(lm_logits.view(-1, lm_logits.size(-1)), lm_labels.view(-1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt').cuda()\n",
    "# model.eval()\n",
    "\n",
    "# Predict all tokens\n",
    "# predictions = model(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = LanguageLearner(text_data, model, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = GPTLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:27 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.837704</th>\n",
       "    <th>5.458471</th>\n",
       "    <th>0.278564</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.450587</th>\n",
       "    <th>5.306539</th>\n",
       "    <th>0.281860</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-4, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:27 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.344717</th>\n",
       "    <th>5.754536</th>\n",
       "    <th>0.283325</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.033213</th>\n",
       "    <th>5.553970</th>\n",
       "    <th>0.275513</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-4, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:27 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.137744</th>\n",
       "    <th>4.836852</th>\n",
       "    <th>0.290771</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.285836</th>\n",
       "    <th>4.576702</th>\n",
       "    <th>0.297974</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-5, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/ubuntu/fastai/fastai/basic_train.py\u001b[0m(23)\u001b[0;36mloss_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     21 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 23 \u001b[0;31m    \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> loss_func\n",
      "functools.partial(<class '__main__.GPTLoss'>, OpenAIGPTLMHeadModel(\n",
      "  (transformer): OpenAIGPTModel(\n",
      "    (embed): Embedding(40990, 768)\n",
      "    (drop): Dropout(p=0.1)\n",
      "    (h): ModuleList(\n",
      "      (0): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): Block(\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1)\n",
      "          (resid_dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): OpenAIGPTLMHead(\n",
      "    (decoder): Linear(in_features=768, out_features=40478, bias=False)\n",
      "  )\n",
      "))\n",
      "--KeyboardInterrupt--\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
