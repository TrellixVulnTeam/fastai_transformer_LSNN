{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like transformer requires really large bptt, otherwise it seems to diverge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "bptt = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH=Path('data/wikitext-2-raw')\n",
    "# data = TextLMDataBunch.load(PATH, cache_name='tmp_200', bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults.text_spec_tok = [PAD,UNK,BOS,FLD,TK_MAJ,TK_UP,TK_REP,TK_WREP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/wikitext-2')\n",
    "# data = TextLMDataBunch.load(PATH, cache_name='tmp_rev', bs=bs, bptt=bptt)\n",
    "data = TextLMDataBunch.load(PATH, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 1\n",
    "# lr = 1e-3\n",
    "momentum = (0.8,0.7)\n",
    "weight_decay = 1.2e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29172"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = data.train_ds.vocab\n",
    "vocab_sz = len(vocab.itos); vocab_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xxbos = xxmaj valkyria xxmaj chronicles xxup iii =',\n",
       " array([   2,   16,    4, 3792,    4, 3857,    5,  884,   16]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = data.train_ds[0][0]\n",
    "t.text[:50], t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob = data.one_batch(); ob[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ob[0]==vocab.stoi[PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos 38th xxmaj ranger xxmaj battalion xxbos xxmaj the xxmaj amylostereaceae are white rot pathogens . xxmaj they xxunk the lignin of the host wood , whereby the infested wood parts become less stable and take a fibrous structure . xxmaj the wood xxunk as fungal enzymes break down and remove the brown - xxunk lignin . xxmaj the distribution in wood takes place mainly along the transport channels in the xxunk . xxmaj if the wood is xxunk , the red rot is vertically positioned , on which xxunk , infested areas contrast with intact wood . xxmaj symptoms of xxunk by the symbiotic partner — wood wasps — include circular exit holes in the crust and acute stress through xxunk , common in hanging , falling'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.textify(ob[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='5%'>  <col width='95%'>  <tr>\n",
       "    <th>idx</th>\n",
       "    <th>text</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>xxbos 38th xxmaj ranger xxmaj battalion xxbos xxmaj the xxmaj amylostereaceae are white rot pathogens . xxmaj they xxunk the lignin of the host wood , whereby the infested wood parts become less stable and take a fibrous structure . xxmaj the wood xxunk as fungal enzymes break down and remove the brown - xxunk lignin . xxmaj the distribution in wood takes place mainly along the transport channels in</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>the biological parents of her adopted daughter xxmaj beth , to be a part of xxmaj beth 's life . xxmaj the director of xxmaj new xxmaj directions , xxmaj will xxmaj schuester ( xxmaj matthew xxmaj morrison ) sets up a \" booty camp \" for the less capable dancers in the club , and auditions for the school musical , xxmaj west xxmaj side xxmaj story , begin</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>appeared to be suffering a minor nervous breakdown . xxmaj political leaders urged xxmaj lady xxmaj rosebery to influence him , but she defended his decision , while stressing that his deterioration in health was only temporary . xxmaj she had to be careful — if it appeared her husband had declined the offer on the grounds that it was too xxunk , it would give substance to the claims</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>an unnamed xxmaj kimmeridgian ( xxmaj late xxmaj jurassic ) formation in xxunk - de - xxmaj calais , xxmaj france , is actually a xxunk , sometimes assigned to xxunk , although the two come from different formations . xxbos xxmaj angelou 's recitation of \" xxmaj on the xxmaj pulse of xxmaj morning \" resulted in more fame and recognition for her previous works , and xxunk her</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>pope 's xxmaj hill , then at the top of xxmaj walker 's xxmaj ridge . xxmaj it was not a large beachhead ; it was under two miles ( 3.2 km ) in length , with a depth around 790 yards ( 720 m ) , and in places only a few yards separated the two sides . xxmaj that evening xxmaj birdwood had been ashore to check on</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import RNNTrainer\n",
    "class TransformerTrainer(LearnerCallback):\n",
    "    def __init__(self, learn, bptt:int, adjust:bool=True):\n",
    "        super().__init__(learn)\n",
    "        self.bptt,self.adjust = bptt,adjust\n",
    "        \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"IN LM, put the training dataloader `first` attribute to `True` to avoid OOM.\"\n",
    "        if hasattr(self.learn.data.train_dl, 'first'):\n",
    "            self.learn.data.first = True\n",
    "            \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        position_ids = torch.arange(last_input.shape[-1], dtype=torch.long, device=last_input.device) + 1\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(last_input)\n",
    "        \n",
    "        if not train and len(last_target.shape) == 1:\n",
    "#             return [1],[123]\n",
    "            return (last_input, position_ids, last_input[:, 1:], position_ids[:, 1:]), last_target\n",
    "        target_ids = torch.arange(last_target.shape[-1], dtype=torch.long, device=last_target.device) + 1\n",
    "        target_ids = target_ids.unsqueeze(0).expand_as(last_target)\n",
    "        \n",
    "        ## STUPID TEST TO SEE IF IT CAN EVEN PREDICT ITSELF\n",
    "#         return (last_input, position_ids, last_target, target_ids), last_target[:, :-1]\n",
    "        return (last_input, position_ids, last_target, target_ids), last_target[:, 1:]\n",
    "    \n",
    "    def on_backward_begin(self, last_loss:Rank0Tensor, last_input:Tensor, **kwargs):\n",
    "        \"Adjusts the lr to the sequence length and applies AR and TAR to `last_loss`.\"\n",
    "        if self.adjust: self.learn.opt.lr *= last_input.size(1) / self.bptt\n",
    "        return last_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Arch\n",
    "Paper: https://arxiv.org/abs/1706.03762  \n",
    "Inspiration: https://github.com/jadore801120/attention-is-all-you-need-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer.Constants as Constants\n",
    "# from dataset import TranslationDataset, paired_collate_fn\n",
    "from transformer.Models import Transformer\n",
    "from transformer.Optim import ScheduledOptim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_src_vocab=vocab_sz,\n",
    "    n_tgt_vocab=vocab_sz,\n",
    "    len_max_seq=data.bptt+data.max_len,\n",
    "    padding_idx=vocab.stoi[PAD]\n",
    "#     len_max_seq=opt.max_token_seq_len,\n",
    "#     tgt_emb_prj_weight_sharing=False,\n",
    "#     emb_src_tgt_weight_sharing=False,\n",
    "#     d_k=opt.d_k,\n",
    "#     d_v=opt.d_v,\n",
    "#     d_model=opt.d_model,\n",
    "#     d_word_vec=opt.d_word_vec,\n",
    "#     d_inner=opt.d_inner_hid,\n",
    "#     n_layers=opt.n_layers,\n",
    "#     n_head=opt.n_head,\n",
    "#     dropout=opt.dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.reset = lambda: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Language learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently model is completely diverging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLanguageLearner(LanguageLearner):\n",
    "    def predict(self, text:str, n_words:int=1, no_unk:bool=True, temperature:float=1., min_p:float=None):\n",
    "        \"Return the `n_words` that come after `text`.\"\n",
    "        ds = self.data.single_dl.dataset\n",
    "#         self.model.reset()\n",
    "        for _ in progress_bar(range(n_words), leave=False):\n",
    "            xb, yb = self.data.one_item(text)\n",
    "            res = self.pred_batch(batch=(xb,yb))[-1]\n",
    "            if no_unk: res[self.data.vocab.stoi[UNK]] = 0.\n",
    "            if min_p is not None: res[res < min_p] = 0.\n",
    "            if temperature != 1.: res.pow_(1 / temperature)\n",
    "            idx = torch.multinomial(res, 1).item()\n",
    "            text += f' {self.data.vocab.itos[idx]}'\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = TransformerLanguageLearner(data, transformer, \n",
    "                        bptt=bptt)\n",
    "#                         bptt=bptt, clip=0.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rt = learn.callbacks[0]\n",
    "learn.callbacks = [\n",
    "    TransformerTrainer(learn, bptt=rt.bptt, adjust=rt.adjust)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp16(loss_scale=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:28 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>5.857947</th>\n",
       "    <th>7.298575</th>\n",
       "    <th>0.121186</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:50 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>5.942202</th>\n",
       "    <th>6.855772</th>\n",
       "    <th>0.121186</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>5.965449</th>\n",
       "    <th>6.697538</th>\n",
       "    <th>0.121186</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-3, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.TransformerTrainer, fastai.callbacks.fp16.MixedPrecision]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(x) for x in learn.callbacks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fp32()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello there how are ceratopsids pitt reusing excommunication confirms niven roasting missed clarify checkpoints'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('hello there how are', n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4032, 29172])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.pred_batch(ob).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([[    2,     4,   629,  ...,   989,    53,     4],\n",
       "          [  700,    13,    38,  ...,    10,     0,    28],\n",
       "          [ 2867,     4,   125,  ...,   366,  4573,     9],\n",
       "          ...,\n",
       "          [   23,   307,    20,  ...,  3554,  1732,     8],\n",
       "          [    4,   230,    94,  ...,    98,   412,  1294],\n",
       "          [    4, 23884,   747,  ..., 11919,     4,  3716]]),\n",
       "  tensor([[  1,   2,   3,  ..., 126, 127, 128],\n",
       "          [  1,   2,   3,  ..., 126, 127, 128],\n",
       "          [  1,   2,   3,  ..., 126, 127, 128],\n",
       "          ...,\n",
       "          [  1,   2,   3,  ..., 126, 127, 128],\n",
       "          [  1,   2,   3,  ..., 126, 127, 128],\n",
       "          [  1,   2,   3,  ..., 126, 127, 128]]),\n",
       "  tensor([[    4,   629,     0,  ...,   989,    53,     4],\n",
       "          [   13,    38,    15,  ...,    10,     0,    28],\n",
       "          [    4,   125,    23,  ...,   366,  4573,     9],\n",
       "          ...,\n",
       "          [  307,    20,   484,  ...,  3554,  1732,     8],\n",
       "          [  230,    94,    10,  ...,    98,   412,  1294],\n",
       "          [23884,   747,   691,  ..., 11919,     4,  3716]]),\n",
       "  tensor([[  2,   3,   4,  ..., 126, 127, 128],\n",
       "          [  2,   3,   4,  ..., 126, 127, 128],\n",
       "          [  2,   3,   4,  ..., 126, 127, 128],\n",
       "          ...,\n",
       "          [  2,   3,   4,  ..., 126, 127, 128],\n",
       "          [  2,   3,   4,  ..., 126, 127, 128],\n",
       "          [  2,   3,   4,  ..., 126, 127, 128]])),\n",
       " tensor([[    4,   629,     0,  ...,    53,     4,   530],\n",
       "         [   13,    38,    15,  ...,     0,    28,   344],\n",
       "         [    4,   125,    23,  ...,  4573,     9,    44],\n",
       "         ...,\n",
       "         [  307,    20,   484,  ...,  1732,     8,   973],\n",
       "         [  230,    94,    10,  ...,   412,  1294,    19],\n",
       "         [23884,   747,   691,  ...,     4,  3716,    17]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_handler = CallbackHandler(learn.callbacks)\n",
    "cb_handler.on_batch_begin(xb, yb, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   17,     4,  9099,  ...,     0,   152,     8],\n",
       "        [   34,   438,    14,  ...,     8,     4, 20235],\n",
       "        [  114,     9,   684,  ...,   156,     4,  2925],\n",
       "        ...,\n",
       "        [    8,     4,   452,  ...,     9, 17910,    56],\n",
       "        [ 5573,   697,    24,  ...,   446,    10,    17],\n",
       "        [   13,    15,   101,  ...,    10,    17,     4]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.TransformerTrainer"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.callbacks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 3 required positional arguments: 'src_pos', 'tgt_seq', and 'tgt_pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a6d48d6a42d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello how are you'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai/text/learner.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text, n_words, no_unk, temperature, min_p)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mno_unk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUNK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_p\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_p\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mpred_batch\u001b[0;34m(self, ds_type, batch, reconstruct)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mcb_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCallbackHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_loss_func2activ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'src_pos', 'tgt_seq', and 'tgt_pos'"
     ]
    }
   ],
   "source": [
    "learn.predict('hello how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/ubuntu/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m(479)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    477 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    478 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 479 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    480 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    481 \u001b[0;31m            \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> up\n",
      "> \u001b[0;32m/home/ubuntu/fastai/fastai/basic_train.py\u001b[0m(19)\u001b[0;36mloss_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     17 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m    \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m    \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> cb_handler\n",
      "CallbackHandler(callbacks=[TransformerTrainer\n",
      "learn: LanguageLearner(data=TextLMDataBunch;\n",
      "\n",
      "Train: LabelList\n",
      "y: LMLabel (23767 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (23767 items)\n",
      "[Text xxbos = xxmaj valkyria xxmaj chronicles xxup iii =, Text xxbos xxmaj senjō no xxmaj valkyria 3 : xxunk xxmaj chronicles ( xxmaj japanese : 戦場のヴァルキュリア3 , lit . xxmaj valkyria of the xxmaj battlefield 3 ) , commonly referred to as xxmaj valkyria xxmaj chronicles xxup iii outside xxmaj japan , is a tactical role - playing video game developed by xxmaj sega and xxmaj media . xxmaj vision for the playstation xxmaj portable . xxmaj released in xxmaj january 2011 in xxmaj japan , it is the third game in the xxmaj valkyria series . xxunk the same fusion of tactical and real - time gameplay as its predecessors , the story runs parallel to the first game and follows the \" xxmaj nameless \" , a penal military unit serving the nation of xxmaj gallia during the xxmaj second xxmaj europan xxmaj war who perform secret black operations and are pitted against the xxmaj imperial unit \" xxunk xxmaj raven \" ., Text xxbos xxmaj the game began development in 2010 , carrying over a large portion of the work done on xxmaj valkyria xxmaj chronicles xxup ii . xxmaj while it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more xxunk for series newcomers . xxmaj character designer xxunk xxmaj honjou and composer xxmaj hitoshi xxmaj sakimoto both returned from previous entries , along with xxmaj valkyria xxmaj chronicles xxup ii director xxmaj takeshi xxmaj ozawa . a large team of writers handled the script . xxmaj the game 's opening theme was sung by xxmaj may ' n ., Text xxbos xxmaj it met with positive sales in xxmaj japan , and was praised by both xxmaj japanese and western critics . xxmaj after release , it received downloadable content , along with an expanded edition in xxmaj november of that year . xxmaj it was also adapted into manga and an original video animation series . xxmaj due to low sales of xxmaj valkyria xxmaj chronicles xxup ii , xxmaj valkyria xxmaj chronicles xxup iii was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . xxmaj media . xxmaj vision would return to the franchise with the development of xxmaj valkyria : xxmaj azure xxmaj revolution for the playstation 4 ., Text xxbos = = xxmaj gameplay = =]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Valid: LabelList\n",
      "y: LMLabel (2461 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2461 items)\n",
      "[Text xxbos = xxmaj homarus gammarus =, Text xxbos xxmaj homarus gammarus , known as the xxmaj european lobster or common lobster , is a species of xxunk lobster from the eastern xxmaj atlantic xxmaj ocean , xxmaj mediterranean xxmaj sea and parts of the xxmaj black xxmaj sea . xxmaj it is closely related to the xxmaj american lobster , xxup h. americanus . xxmaj it may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . xxmaj in life , the lobsters are blue , only becoming \" lobster red \" on cooking . xxmaj mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into xxunk larvae . xxmaj homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the xxmaj british xxmaj isles ., Text xxbos = = xxmaj description = =, Text xxbos xxmaj homarus gammarus is a large xxunk , with a body length up to 60 centimetres ( 24 in ) and weighing up to 5 – 6 kilograms ( 11 – 13 lb ) , although the lobsters caught in lobster pots are usually 23 – 38 cm ( 9 – 15 in ) long and weigh 0.7 – 2.2 kg ( 1.5 – 4.9 lb ) . xxmaj like other crustaceans , lobsters have a hard xxunk which they must shed in order to grow , in a process called xxunk ( xxunk ) . xxmaj this may occur several times a year for young lobsters , but decreases to once every 1 – 2 years for larger animals ., Text xxbos xxmaj the first pair of xxunk is armed with a large , asymmetrical pair of claws . xxmaj the larger one is the \" xxunk \" , and has rounded xxunk used for crushing prey ; the other is the \" cutter \" , which has sharp inner edges , and is used for holding or tearing the prey . xxmaj usually , the left claw is the xxunk , and the right is the cutter .]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Test: LabelList\n",
      "y: LMLabel (2891 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2891 items)\n",
      "[Text xxbos = xxmaj robert xxunk =, Text xxbos xxmaj robert xxunk is an xxmaj english film , television and theatre actor . xxmaj he had a guest - starring role on the television series xxmaj the xxmaj bill in 2000 . xxmaj this was followed by a starring role in the play xxmaj herons written by xxmaj simon xxmaj stephens , which was performed in 2001 at the xxmaj royal xxmaj court xxmaj theatre . xxmaj he had a guest role in the television series xxmaj judge xxmaj john xxunk in 2002 . xxmaj in 2004 xxunk landed a role as \" xxmaj craig \" in the episode \" xxmaj teddy 's xxmaj story \" of the television series xxmaj the xxmaj long xxmaj firm ; he starred alongside actors xxmaj mark xxmaj strong and xxmaj derek xxmaj jacobi . xxmaj he was cast in the 2005 theatre productions of the xxmaj philip xxmaj ridley play xxmaj mercury xxmaj fur , which was performed at the xxmaj drum xxmaj theatre in xxmaj plymouth and the xxunk xxunk xxmaj factory in xxmaj london . xxmaj he was directed by xxmaj john xxunk and starred alongside xxmaj ben xxunk , xxmaj shane xxunk , xxmaj harry xxmaj kent , xxmaj fraser xxunk , xxmaj sophie xxmaj stanton and xxmaj dominic xxmaj hall ., Text xxbos xxmaj in 2006 , xxunk starred alongside xxunk in the play xxunk written by xxmaj mark xxunk . xxmaj he appeared on a 2006 episode of the television series , xxmaj doctors , followed by a role in the 2007 theatre production of xxmaj how to xxmaj curse directed by xxunk xxunk . xxmaj how to xxmaj curse was performed at xxmaj bush xxmaj theatre in the xxmaj london xxmaj borough of xxunk and xxmaj fulham . xxunk starred in two films in 2008 , xxunk xxunk by filmmaker xxmaj paris xxunk , and xxunk xxmaj punch directed by xxunk xxmaj blackburn . xxmaj in xxmaj may 2008 , xxunk made a guest appearance on a two - part episode arc of the television series xxmaj waking the xxmaj dead , followed by an appearance on the television series xxunk in xxmaj november 2008 . xxmaj he had a recurring role in ten episodes of the television series xxunk in 2010 , as \" xxunk xxmaj fletcher \" . xxunk starred in the 2011 film xxunk directed by xxmaj paris xxunk ., Text xxbos = = xxmaj career = =, Text xxbos = = = 2000 – 2005 = = =]...\n",
      "Path: data/wikitext-2, model=Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (dropout_emb): Dropout(p=0.1)\n",
      "    (src_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (tgt_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tgt_word_prj): Linear(in_features=512, out_features=29172, bias=False)\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f7a78dd9780>, metrics=[<function accuracy at 0x7f79d2677620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data/wikitext-2'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[TransformerTrainer\n",
      "learn: LanguageLearner(data=TextLMDataBunch;\n",
      "\n",
      "Train: LabelList\n",
      "y: LMLabel (23767 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (23767 items)\n",
      "[Text xxbos = xxmaj valkyria xxmaj chronicles xxup iii =, Text xxbos xxmaj senjō no xxmaj valkyria 3 : xxunk xxmaj chronicles ( xxmaj japanese : 戦場のヴァルキュリア3 , lit . xxmaj valkyria of the xxmaj battlefield 3 ) , commonly referred to as xxmaj valkyria xxmaj chronicles xxup iii outside xxmaj japan , is a tactical role - playing video game developed by xxmaj sega and xxmaj media . xxmaj vision for the playstation xxmaj portable . xxmaj released in xxmaj january 2011 in xxmaj japan , it is the third game in the xxmaj valkyria series . xxunk the same fusion of tactical and real - time gameplay as its predecessors , the story runs parallel to the first game and follows the \" xxmaj nameless \" , a penal military unit serving the nation of xxmaj gallia during the xxmaj second xxmaj europan xxmaj war who perform secret black operations and are pitted against the xxmaj imperial unit \" xxunk xxmaj raven \" ., Text xxbos xxmaj the game began development in 2010 , carrying over a large portion of the work done on xxmaj valkyria xxmaj chronicles xxup ii . xxmaj while it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more xxunk for series newcomers . xxmaj character designer xxunk xxmaj honjou and composer xxmaj hitoshi xxmaj sakimoto both returned from previous entries , along with xxmaj valkyria xxmaj chronicles xxup ii director xxmaj takeshi xxmaj ozawa . a large team of writers handled the script . xxmaj the game 's opening theme was sung by xxmaj may ' n ., Text xxbos xxmaj it met with positive sales in xxmaj japan , and was praised by both xxmaj japanese and western critics . xxmaj after release , it received downloadable content , along with an expanded edition in xxmaj november of that year . xxmaj it was also adapted into manga and an original video animation series . xxmaj due to low sales of xxmaj valkyria xxmaj chronicles xxup ii , xxmaj valkyria xxmaj chronicles xxup iii was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . xxmaj media . xxmaj vision would return to the franchise with the development of xxmaj valkyria : xxmaj azure xxmaj revolution for the playstation 4 ., Text xxbos = = xxmaj gameplay = =]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Valid: LabelList\n",
      "y: LMLabel (2461 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2461 items)\n",
      "[Text xxbos = xxmaj homarus gammarus =, Text xxbos xxmaj homarus gammarus , known as the xxmaj european lobster or common lobster , is a species of xxunk lobster from the eastern xxmaj atlantic xxmaj ocean , xxmaj mediterranean xxmaj sea and parts of the xxmaj black xxmaj sea . xxmaj it is closely related to the xxmaj american lobster , xxup h. americanus . xxmaj it may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . xxmaj in life , the lobsters are blue , only becoming \" lobster red \" on cooking . xxmaj mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into xxunk larvae . xxmaj homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the xxmaj british xxmaj isles ., Text xxbos = = xxmaj description = =, Text xxbos xxmaj homarus gammarus is a large xxunk , with a body length up to 60 centimetres ( 24 in ) and weighing up to 5 – 6 kilograms ( 11 – 13 lb ) , although the lobsters caught in lobster pots are usually 23 – 38 cm ( 9 – 15 in ) long and weigh 0.7 – 2.2 kg ( 1.5 – 4.9 lb ) . xxmaj like other crustaceans , lobsters have a hard xxunk which they must shed in order to grow , in a process called xxunk ( xxunk ) . xxmaj this may occur several times a year for young lobsters , but decreases to once every 1 – 2 years for larger animals ., Text xxbos xxmaj the first pair of xxunk is armed with a large , asymmetrical pair of claws . xxmaj the larger one is the \" xxunk \" , and has rounded xxunk used for crushing prey ; the other is the \" cutter \" , which has sharp inner edges , and is used for holding or tearing the prey . xxmaj usually , the left claw is the xxunk , and the right is the cutter .]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Test: LabelList\n",
      "y: LMLabel (2891 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2891 items)\n",
      "[Text xxbos = xxmaj robert xxunk =, Text xxbos xxmaj robert xxunk is an xxmaj english film , television and theatre actor . xxmaj he had a guest - starring role on the television series xxmaj the xxmaj bill in 2000 . xxmaj this was followed by a starring role in the play xxmaj herons written by xxmaj simon xxmaj stephens , which was performed in 2001 at the xxmaj royal xxmaj court xxmaj theatre . xxmaj he had a guest role in the television series xxmaj judge xxmaj john xxunk in 2002 . xxmaj in 2004 xxunk landed a role as \" xxmaj craig \" in the episode \" xxmaj teddy 's xxmaj story \" of the television series xxmaj the xxmaj long xxmaj firm ; he starred alongside actors xxmaj mark xxmaj strong and xxmaj derek xxmaj jacobi . xxmaj he was cast in the 2005 theatre productions of the xxmaj philip xxmaj ridley play xxmaj mercury xxmaj fur , which was performed at the xxmaj drum xxmaj theatre in xxmaj plymouth and the xxunk xxunk xxmaj factory in xxmaj london . xxmaj he was directed by xxmaj john xxunk and starred alongside xxmaj ben xxunk , xxmaj shane xxunk , xxmaj harry xxmaj kent , xxmaj fraser xxunk , xxmaj sophie xxmaj stanton and xxmaj dominic xxmaj hall ., Text xxbos xxmaj in 2006 , xxunk starred alongside xxunk in the play xxunk written by xxmaj mark xxunk . xxmaj he appeared on a 2006 episode of the television series , xxmaj doctors , followed by a role in the 2007 theatre production of xxmaj how to xxmaj curse directed by xxunk xxunk . xxmaj how to xxmaj curse was performed at xxmaj bush xxmaj theatre in the xxmaj london xxmaj borough of xxunk and xxmaj fulham . xxunk starred in two films in 2008 , xxunk xxunk by filmmaker xxmaj paris xxunk , and xxunk xxmaj punch directed by xxunk xxmaj blackburn . xxmaj in xxmaj may 2008 , xxunk made a guest appearance on a two - part episode arc of the television series xxmaj waking the xxmaj dead , followed by an appearance on the television series xxunk in xxmaj november 2008 . xxmaj he had a recurring role in ten episodes of the television series xxunk in 2010 , as \" xxunk xxmaj fletcher \" . xxunk starred in the 2011 film xxunk directed by xxmaj paris xxunk ., Text xxbos = = xxmaj career = =, Text xxbos = = = 2000 – 2005 = = =]...\n",
      "Path: data/wikitext-2, model=Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (dropout_emb): Dropout(p=0.1)\n",
      "    (src_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (tgt_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tgt_word_prj): Linear(in_features=512, out_features=29172, bias=False)\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f7a78dd9780>, metrics=[<function accuracy at 0x7f79d2677620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data/wikitext-2'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
      "  (0): Dropout(p=0.1)\n",
      "  (1): Embedding(29172, 512, padding_idx=1)\n",
      "  (2): Embedding(154, 512)\n",
      "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Softmax()\n",
      "  (8): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (9): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "  (11): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (12): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (13): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (14): Dropout(p=0.1)\n",
      "  (15): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (17): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (18): Dropout(p=0.1)\n",
      "  (19): Softmax()\n",
      "  (20): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (21): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (22): Dropout(p=0.1)\n",
      "  (23): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (24): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (25): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (26): Dropout(p=0.1)\n",
      "  (27): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (28): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (29): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (30): Dropout(p=0.1)\n",
      "  (31): Softmax()\n",
      "  (32): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (33): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (34): Dropout(p=0.1)\n",
      "  (35): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (36): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (37): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (38): Dropout(p=0.1)\n",
      "  (39): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (40): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (41): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (42): Dropout(p=0.1)\n",
      "  (43): Softmax()\n",
      "  (44): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (45): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (46): Dropout(p=0.1)\n",
      "  (47): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (48): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (49): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (50): Dropout(p=0.1)\n",
      "  (51): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (52): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (53): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (54): Dropout(p=0.1)\n",
      "  (55): Softmax()\n",
      "  (56): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (57): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (58): Dropout(p=0.1)\n",
      "  (59): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (60): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (61): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (62): Dropout(p=0.1)\n",
      "  (63): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (64): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (65): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (66): Dropout(p=0.1)\n",
      "  (67): Softmax()\n",
      "  (68): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (69): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (70): Dropout(p=0.1)\n",
      "  (71): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (72): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (73): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (74): Dropout(p=0.1)\n",
      "  (75): Embedding(29172, 512, padding_idx=1)\n",
      "  (76): Embedding(154, 512)\n",
      "  (77): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (78): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (79): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (80): Dropout(p=0.1)\n",
      "  (81): Softmax()\n",
      "  (82): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (83): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (84): Dropout(p=0.1)\n",
      "  (85): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (86): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (87): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (88): Dropout(p=0.1)\n",
      "  (89): Softmax()\n",
      "  (90): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (91): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (92): Dropout(p=0.1)\n",
      "  (93): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (94): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (95): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (96): Dropout(p=0.1)\n",
      "  (97): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (98): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (99): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (100): Dropout(p=0.1)\n",
      "  (101): Softmax()\n",
      "  (102): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (103): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (104): Dropout(p=0.1)\n",
      "  (105): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (106): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (107): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (108): Dropout(p=0.1)\n",
      "  (109): Softmax()\n",
      "  (110): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (111): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (112): Dropout(p=0.1)\n",
      "  (113): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (114): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (115): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (116): Dropout(p=0.1)\n",
      "  (117): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (118): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (119): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (120): Dropout(p=0.1)\n",
      "  (121): Softmax()\n",
      "  (122): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (123): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (124): Dropout(p=0.1)\n",
      "  (125): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (126): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (127): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (128): Dropout(p=0.1)\n",
      "  (129): Softmax()\n",
      "  (130): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (131): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (132): Dropout(p=0.1)\n",
      "  (133): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (134): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (135): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (136): Dropout(p=0.1)\n",
      "  (137): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (138): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (139): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (140): Dropout(p=0.1)\n",
      "  (141): Softmax()\n",
      "  (142): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (143): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (144): Dropout(p=0.1)\n",
      "  (145): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (146): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (147): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (148): Dropout(p=0.1)\n",
      "  (149): Softmax()\n",
      "  (150): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (151): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (152): Dropout(p=0.1)\n",
      "  (153): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (154): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (155): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (156): Dropout(p=0.1)\n",
      "  (157): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (158): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (159): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (160): Dropout(p=0.1)\n",
      "  (161): Softmax()\n",
      "  (162): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (163): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (164): Dropout(p=0.1)\n",
      "  (165): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (166): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (167): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (168): Dropout(p=0.1)\n",
      "  (169): Softmax()\n",
      "  (170): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (171): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (172): Dropout(p=0.1)\n",
      "  (173): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (174): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (175): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (176): Dropout(p=0.1)\n",
      "  (177): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (178): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (179): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (180): Dropout(p=0.1)\n",
      "  (181): Softmax()\n",
      "  (182): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (183): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (184): Dropout(p=0.1)\n",
      "  (185): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (186): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (187): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (188): Dropout(p=0.1)\n",
      "  (189): Softmax()\n",
      "  (190): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (191): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (192): Dropout(p=0.1)\n",
      "  (193): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (194): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (195): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (196): Dropout(p=0.1)\n",
      "  (197): Linear(in_features=512, out_features=29172, bias=False)\n",
      ")])\n",
      "bptt: 128\n",
      "adjust: False, MixedPrecision\n",
      "learn: LanguageLearner(data=TextLMDataBunch;\n",
      "\n",
      "Train: LabelList\n",
      "y: LMLabel (23767 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (23767 items)\n",
      "[Text xxbos = xxmaj valkyria xxmaj chronicles xxup iii =, Text xxbos xxmaj senjō no xxmaj valkyria 3 : xxunk xxmaj chronicles ( xxmaj japanese : 戦場のヴァルキュリア3 , lit . xxmaj valkyria of the xxmaj battlefield 3 ) , commonly referred to as xxmaj valkyria xxmaj chronicles xxup iii outside xxmaj japan , is a tactical role - playing video game developed by xxmaj sega and xxmaj media . xxmaj vision for the playstation xxmaj portable . xxmaj released in xxmaj january 2011 in xxmaj japan , it is the third game in the xxmaj valkyria series . xxunk the same fusion of tactical and real - time gameplay as its predecessors , the story runs parallel to the first game and follows the \" xxmaj nameless \" , a penal military unit serving the nation of xxmaj gallia during the xxmaj second xxmaj europan xxmaj war who perform secret black operations and are pitted against the xxmaj imperial unit \" xxunk xxmaj raven \" ., Text xxbos xxmaj the game began development in 2010 , carrying over a large portion of the work done on xxmaj valkyria xxmaj chronicles xxup ii . xxmaj while it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more xxunk for series newcomers . xxmaj character designer xxunk xxmaj honjou and composer xxmaj hitoshi xxmaj sakimoto both returned from previous entries , along with xxmaj valkyria xxmaj chronicles xxup ii director xxmaj takeshi xxmaj ozawa . a large team of writers handled the script . xxmaj the game 's opening theme was sung by xxmaj may ' n ., Text xxbos xxmaj it met with positive sales in xxmaj japan , and was praised by both xxmaj japanese and western critics . xxmaj after release , it received downloadable content , along with an expanded edition in xxmaj november of that year . xxmaj it was also adapted into manga and an original video animation series . xxmaj due to low sales of xxmaj valkyria xxmaj chronicles xxup ii , xxmaj valkyria xxmaj chronicles xxup iii was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . xxmaj media . xxmaj vision would return to the franchise with the development of xxmaj valkyria : xxmaj azure xxmaj revolution for the playstation 4 ., Text xxbos = = xxmaj gameplay = =]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Valid: LabelList\n",
      "y: LMLabel (2461 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2461 items)\n",
      "[Text xxbos = xxmaj homarus gammarus =, Text xxbos xxmaj homarus gammarus , known as the xxmaj european lobster or common lobster , is a species of xxunk lobster from the eastern xxmaj atlantic xxmaj ocean , xxmaj mediterranean xxmaj sea and parts of the xxmaj black xxmaj sea . xxmaj it is closely related to the xxmaj american lobster , xxup h. americanus . xxmaj it may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . xxmaj in life , the lobsters are blue , only becoming \" lobster red \" on cooking . xxmaj mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into xxunk larvae . xxmaj homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the xxmaj british xxmaj isles ., Text xxbos = = xxmaj description = =, Text xxbos xxmaj homarus gammarus is a large xxunk , with a body length up to 60 centimetres ( 24 in ) and weighing up to 5 – 6 kilograms ( 11 – 13 lb ) , although the lobsters caught in lobster pots are usually 23 – 38 cm ( 9 – 15 in ) long and weigh 0.7 – 2.2 kg ( 1.5 – 4.9 lb ) . xxmaj like other crustaceans , lobsters have a hard xxunk which they must shed in order to grow , in a process called xxunk ( xxunk ) . xxmaj this may occur several times a year for young lobsters , but decreases to once every 1 – 2 years for larger animals ., Text xxbos xxmaj the first pair of xxunk is armed with a large , asymmetrical pair of claws . xxmaj the larger one is the \" xxunk \" , and has rounded xxunk used for crushing prey ; the other is the \" cutter \" , which has sharp inner edges , and is used for holding or tearing the prey . xxmaj usually , the left claw is the xxunk , and the right is the cutter .]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Test: LabelList\n",
      "y: LMLabel (2891 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2891 items)\n",
      "[Text xxbos = xxmaj robert xxunk =, Text xxbos xxmaj robert xxunk is an xxmaj english film , television and theatre actor . xxmaj he had a guest - starring role on the television series xxmaj the xxmaj bill in 2000 . xxmaj this was followed by a starring role in the play xxmaj herons written by xxmaj simon xxmaj stephens , which was performed in 2001 at the xxmaj royal xxmaj court xxmaj theatre . xxmaj he had a guest role in the television series xxmaj judge xxmaj john xxunk in 2002 . xxmaj in 2004 xxunk landed a role as \" xxmaj craig \" in the episode \" xxmaj teddy 's xxmaj story \" of the television series xxmaj the xxmaj long xxmaj firm ; he starred alongside actors xxmaj mark xxmaj strong and xxmaj derek xxmaj jacobi . xxmaj he was cast in the 2005 theatre productions of the xxmaj philip xxmaj ridley play xxmaj mercury xxmaj fur , which was performed at the xxmaj drum xxmaj theatre in xxmaj plymouth and the xxunk xxunk xxmaj factory in xxmaj london . xxmaj he was directed by xxmaj john xxunk and starred alongside xxmaj ben xxunk , xxmaj shane xxunk , xxmaj harry xxmaj kent , xxmaj fraser xxunk , xxmaj sophie xxmaj stanton and xxmaj dominic xxmaj hall ., Text xxbos xxmaj in 2006 , xxunk starred alongside xxunk in the play xxunk written by xxmaj mark xxunk . xxmaj he appeared on a 2006 episode of the television series , xxmaj doctors , followed by a role in the 2007 theatre production of xxmaj how to xxmaj curse directed by xxunk xxunk . xxmaj how to xxmaj curse was performed at xxmaj bush xxmaj theatre in the xxmaj london xxmaj borough of xxunk and xxmaj fulham . xxunk starred in two films in 2008 , xxunk xxunk by filmmaker xxmaj paris xxunk , and xxunk xxmaj punch directed by xxunk xxmaj blackburn . xxmaj in xxmaj may 2008 , xxunk made a guest appearance on a two - part episode arc of the television series xxmaj waking the xxmaj dead , followed by an appearance on the television series xxunk in xxmaj november 2008 . xxmaj he had a recurring role in ten episodes of the television series xxunk in 2010 , as \" xxunk xxmaj fletcher \" . xxunk starred in the 2011 film xxunk directed by xxmaj paris xxunk ., Text xxbos = = xxmaj career = =, Text xxbos = = = 2000 – 2005 = = =]...\n",
      "Path: data/wikitext-2, model=Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (dropout_emb): Dropout(p=0.1)\n",
      "    (src_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (tgt_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tgt_word_prj): Linear(in_features=512, out_features=29172, bias=False)\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f7a78dd9780>, metrics=[<function accuracy at 0x7f79d2677620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data/wikitext-2'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
      "  (0): Dropout(p=0.1)\n",
      "  (1): Embedding(29172, 512, padding_idx=1)\n",
      "  (2): Embedding(154, 512)\n",
      "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Softmax()\n",
      "  (8): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (9): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "  (11): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (12): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (13): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (14): Dropout(p=0.1)\n",
      "  (15): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (17): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (18): Dropout(p=0.1)\n",
      "  (19): Softmax()\n",
      "  (20): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (21): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (22): Dropout(p=0.1)\n",
      "  (23): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (24): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (25): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (26): Dropout(p=0.1)\n",
      "  (27): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (28): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (29): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (30): Dropout(p=0.1)\n",
      "  (31): Softmax()\n",
      "  (32): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (33): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (34): Dropout(p=0.1)\n",
      "  (35): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (36): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (37): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (38): Dropout(p=0.1)\n",
      "  (39): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (40): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (41): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (42): Dropout(p=0.1)\n",
      "  (43): Softmax()\n",
      "  (44): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (45): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (46): Dropout(p=0.1)\n",
      "  (47): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (48): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (49): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (50): Dropout(p=0.1)\n",
      "  (51): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (52): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (53): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (54): Dropout(p=0.1)\n",
      "  (55): Softmax()\n",
      "  (56): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (57): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (58): Dropout(p=0.1)\n",
      "  (59): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (60): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (61): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (62): Dropout(p=0.1)\n",
      "  (63): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (64): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (65): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (66): Dropout(p=0.1)\n",
      "  (67): Softmax()\n",
      "  (68): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (69): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (70): Dropout(p=0.1)\n",
      "  (71): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (72): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (73): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (74): Dropout(p=0.1)\n",
      "  (75): Embedding(29172, 512, padding_idx=1)\n",
      "  (76): Embedding(154, 512)\n",
      "  (77): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (78): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (79): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (80): Dropout(p=0.1)\n",
      "  (81): Softmax()\n",
      "  (82): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (83): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (84): Dropout(p=0.1)\n",
      "  (85): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (86): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (87): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (88): Dropout(p=0.1)\n",
      "  (89): Softmax()\n",
      "  (90): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (91): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (92): Dropout(p=0.1)\n",
      "  (93): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (94): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (95): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (96): Dropout(p=0.1)\n",
      "  (97): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (98): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (99): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (100): Dropout(p=0.1)\n",
      "  (101): Softmax()\n",
      "  (102): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (103): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (104): Dropout(p=0.1)\n",
      "  (105): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (106): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (107): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (108): Dropout(p=0.1)\n",
      "  (109): Softmax()\n",
      "  (110): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (111): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (112): Dropout(p=0.1)\n",
      "  (113): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (114): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (115): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (116): Dropout(p=0.1)\n",
      "  (117): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (118): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (119): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (120): Dropout(p=0.1)\n",
      "  (121): Softmax()\n",
      "  (122): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (123): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (124): Dropout(p=0.1)\n",
      "  (125): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (126): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (127): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (128): Dropout(p=0.1)\n",
      "  (129): Softmax()\n",
      "  (130): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (131): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (132): Dropout(p=0.1)\n",
      "  (133): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (134): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (135): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (136): Dropout(p=0.1)\n",
      "  (137): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (138): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (139): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (140): Dropout(p=0.1)\n",
      "  (141): Softmax()\n",
      "  (142): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (143): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (144): Dropout(p=0.1)\n",
      "  (145): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (146): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (147): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (148): Dropout(p=0.1)\n",
      "  (149): Softmax()\n",
      "  (150): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (151): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (152): Dropout(p=0.1)\n",
      "  (153): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (154): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (155): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (156): Dropout(p=0.1)\n",
      "  (157): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (158): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (159): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (160): Dropout(p=0.1)\n",
      "  (161): Softmax()\n",
      "  (162): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (163): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (164): Dropout(p=0.1)\n",
      "  (165): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (166): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (167): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (168): Dropout(p=0.1)\n",
      "  (169): Softmax()\n",
      "  (170): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (171): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (172): Dropout(p=0.1)\n",
      "  (173): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (174): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (175): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (176): Dropout(p=0.1)\n",
      "  (177): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (178): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (179): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (180): Dropout(p=0.1)\n",
      "  (181): Softmax()\n",
      "  (182): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (183): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (184): Dropout(p=0.1)\n",
      "  (185): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (186): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (187): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (188): Dropout(p=0.1)\n",
      "  (189): Softmax()\n",
      "  (190): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (191): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (192): Dropout(p=0.1)\n",
      "  (193): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (194): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (195): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (196): Dropout(p=0.1)\n",
      "  (197): Linear(in_features=512, out_features=29172, bias=False)\n",
      ")])\n",
      "loss_scale: 256\n",
      "flat_master: False], layer_groups=[Sequential(\n",
      "  (0): Dropout(p=0.1)\n",
      "  (1): Embedding(29172, 512, padding_idx=1)\n",
      "  (2): Embedding(154, 512)\n",
      "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Softmax()\n",
      "  (8): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (9): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "  (11): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (12): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (13): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (14): Dropout(p=0.1)\n",
      "  (15): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (17): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (18): Dropout(p=0.1)\n",
      "  (19): Softmax()\n",
      "  (20): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (21): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (22): Dropout(p=0.1)\n",
      "  (23): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (24): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (25): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (26): Dropout(p=0.1)\n",
      "  (27): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (28): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (29): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (30): Dropout(p=0.1)\n",
      "  (31): Softmax()\n",
      "  (32): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (33): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (34): Dropout(p=0.1)\n",
      "  (35): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (36): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (37): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (38): Dropout(p=0.1)\n",
      "  (39): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (40): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (41): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (42): Dropout(p=0.1)\n",
      "  (43): Softmax()\n",
      "  (44): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (45): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (46): Dropout(p=0.1)\n",
      "  (47): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (48): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (49): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (50): Dropout(p=0.1)\n",
      "  (51): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (52): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (53): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (54): Dropout(p=0.1)\n",
      "  (55): Softmax()\n",
      "  (56): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (57): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (58): Dropout(p=0.1)\n",
      "  (59): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (60): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (61): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (62): Dropout(p=0.1)\n",
      "  (63): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (64): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (65): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (66): Dropout(p=0.1)\n",
      "  (67): Softmax()\n",
      "  (68): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (69): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (70): Dropout(p=0.1)\n",
      "  (71): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (72): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (73): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (74): Dropout(p=0.1)\n",
      "  (75): Embedding(29172, 512, padding_idx=1)\n",
      "  (76): Embedding(154, 512)\n",
      "  (77): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (78): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (79): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (80): Dropout(p=0.1)\n",
      "  (81): Softmax()\n",
      "  (82): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (83): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (84): Dropout(p=0.1)\n",
      "  (85): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (86): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (87): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (88): Dropout(p=0.1)\n",
      "  (89): Softmax()\n",
      "  (90): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (91): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (92): Dropout(p=0.1)\n",
      "  (93): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (94): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (95): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (96): Dropout(p=0.1)\n",
      "  (97): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (98): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (99): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (100): Dropout(p=0.1)\n",
      "  (101): Softmax()\n",
      "  (102): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (103): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (104): Dropout(p=0.1)\n",
      "  (105): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (106): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (107): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (108): Dropout(p=0.1)\n",
      "  (109): Softmax()\n",
      "  (110): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (111): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (112): Dropout(p=0.1)\n",
      "  (113): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (114): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (115): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (116): Dropout(p=0.1)\n",
      "  (117): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (118): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (119): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (120): Dropout(p=0.1)\n",
      "  (121): Softmax()\n",
      "  (122): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (123): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (124): Dropout(p=0.1)\n",
      "  (125): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (126): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (127): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (128): Dropout(p=0.1)\n",
      "  (129): Softmax()\n",
      "  (130): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (131): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (132): Dropout(p=0.1)\n",
      "  (133): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (134): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (135): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (136): Dropout(p=0.1)\n",
      "  (137): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (138): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (139): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (140): Dropout(p=0.1)\n",
      "  (141): Softmax()\n",
      "  (142): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (143): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (144): Dropout(p=0.1)\n",
      "  (145): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (146): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (147): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (148): Dropout(p=0.1)\n",
      "  (149): Softmax()\n",
      "  (150): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (151): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (152): Dropout(p=0.1)\n",
      "  (153): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (154): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (155): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (156): Dropout(p=0.1)\n",
      "  (157): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (158): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (159): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (160): Dropout(p=0.1)\n",
      "  (161): Softmax()\n",
      "  (162): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (163): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (164): Dropout(p=0.1)\n",
      "  (165): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (166): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (167): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (168): Dropout(p=0.1)\n",
      "  (169): Softmax()\n",
      "  (170): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (171): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (172): Dropout(p=0.1)\n",
      "  (173): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (174): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (175): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (176): Dropout(p=0.1)\n",
      "  (177): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (178): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (179): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (180): Dropout(p=0.1)\n",
      "  (181): Softmax()\n",
      "  (182): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (183): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (184): Dropout(p=0.1)\n",
      "  (185): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (186): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (187): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (188): Dropout(p=0.1)\n",
      "  (189): Softmax()\n",
      "  (190): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (191): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (192): Dropout(p=0.1)\n",
      "  (193): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (194): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (195): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (196): Dropout(p=0.1)\n",
      "  (197): Linear(in_features=512, out_features=29172, bias=False)\n",
      ")])\n",
      "bptt: 128\n",
      "adjust: False, MixedPrecision\n",
      "learn: LanguageLearner(data=TextLMDataBunch;\n",
      "\n",
      "Train: LabelList\n",
      "y: LMLabel (23767 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (23767 items)\n",
      "[Text xxbos = xxmaj valkyria xxmaj chronicles xxup iii =, Text xxbos xxmaj senjō no xxmaj valkyria 3 : xxunk xxmaj chronicles ( xxmaj japanese : 戦場のヴァルキュリア3 , lit . xxmaj valkyria of the xxmaj battlefield 3 ) , commonly referred to as xxmaj valkyria xxmaj chronicles xxup iii outside xxmaj japan , is a tactical role - playing video game developed by xxmaj sega and xxmaj media . xxmaj vision for the playstation xxmaj portable . xxmaj released in xxmaj january 2011 in xxmaj japan , it is the third game in the xxmaj valkyria series . xxunk the same fusion of tactical and real - time gameplay as its predecessors , the story runs parallel to the first game and follows the \" xxmaj nameless \" , a penal military unit serving the nation of xxmaj gallia during the xxmaj second xxmaj europan xxmaj war who perform secret black operations and are pitted against the xxmaj imperial unit \" xxunk xxmaj raven \" ., Text xxbos xxmaj the game began development in 2010 , carrying over a large portion of the work done on xxmaj valkyria xxmaj chronicles xxup ii . xxmaj while it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more xxunk for series newcomers . xxmaj character designer xxunk xxmaj honjou and composer xxmaj hitoshi xxmaj sakimoto both returned from previous entries , along with xxmaj valkyria xxmaj chronicles xxup ii director xxmaj takeshi xxmaj ozawa . a large team of writers handled the script . xxmaj the game 's opening theme was sung by xxmaj may ' n ., Text xxbos xxmaj it met with positive sales in xxmaj japan , and was praised by both xxmaj japanese and western critics . xxmaj after release , it received downloadable content , along with an expanded edition in xxmaj november of that year . xxmaj it was also adapted into manga and an original video animation series . xxmaj due to low sales of xxmaj valkyria xxmaj chronicles xxup ii , xxmaj valkyria xxmaj chronicles xxup iii was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . xxmaj media . xxmaj vision would return to the franchise with the development of xxmaj valkyria : xxmaj azure xxmaj revolution for the playstation 4 ., Text xxbos = = xxmaj gameplay = =]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Valid: LabelList\n",
      "y: LMLabel (2461 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2461 items)\n",
      "[Text xxbos = xxmaj homarus gammarus =, Text xxbos xxmaj homarus gammarus , known as the xxmaj european lobster or common lobster , is a species of xxunk lobster from the eastern xxmaj atlantic xxmaj ocean , xxmaj mediterranean xxmaj sea and parts of the xxmaj black xxmaj sea . xxmaj it is closely related to the xxmaj american lobster , xxup h. americanus . xxmaj it may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . xxmaj in life , the lobsters are blue , only becoming \" lobster red \" on cooking . xxmaj mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into xxunk larvae . xxmaj homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the xxmaj british xxmaj isles ., Text xxbos = = xxmaj description = =, Text xxbos xxmaj homarus gammarus is a large xxunk , with a body length up to 60 centimetres ( 24 in ) and weighing up to 5 – 6 kilograms ( 11 – 13 lb ) , although the lobsters caught in lobster pots are usually 23 – 38 cm ( 9 – 15 in ) long and weigh 0.7 – 2.2 kg ( 1.5 – 4.9 lb ) . xxmaj like other crustaceans , lobsters have a hard xxunk which they must shed in order to grow , in a process called xxunk ( xxunk ) . xxmaj this may occur several times a year for young lobsters , but decreases to once every 1 – 2 years for larger animals ., Text xxbos xxmaj the first pair of xxunk is armed with a large , asymmetrical pair of claws . xxmaj the larger one is the \" xxunk \" , and has rounded xxunk used for crushing prey ; the other is the \" cutter \" , which has sharp inner edges , and is used for holding or tearing the prey . xxmaj usually , the left claw is the xxunk , and the right is the cutter .]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Test: LabelList\n",
      "y: LMLabel (2891 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2891 items)\n",
      "[Text xxbos = xxmaj robert xxunk =, Text xxbos xxmaj robert xxunk is an xxmaj english film , television and theatre actor . xxmaj he had a guest - starring role on the television series xxmaj the xxmaj bill in 2000 . xxmaj this was followed by a starring role in the play xxmaj herons written by xxmaj simon xxmaj stephens , which was performed in 2001 at the xxmaj royal xxmaj court xxmaj theatre . xxmaj he had a guest role in the television series xxmaj judge xxmaj john xxunk in 2002 . xxmaj in 2004 xxunk landed a role as \" xxmaj craig \" in the episode \" xxmaj teddy 's xxmaj story \" of the television series xxmaj the xxmaj long xxmaj firm ; he starred alongside actors xxmaj mark xxmaj strong and xxmaj derek xxmaj jacobi . xxmaj he was cast in the 2005 theatre productions of the xxmaj philip xxmaj ridley play xxmaj mercury xxmaj fur , which was performed at the xxmaj drum xxmaj theatre in xxmaj plymouth and the xxunk xxunk xxmaj factory in xxmaj london . xxmaj he was directed by xxmaj john xxunk and starred alongside xxmaj ben xxunk , xxmaj shane xxunk , xxmaj harry xxmaj kent , xxmaj fraser xxunk , xxmaj sophie xxmaj stanton and xxmaj dominic xxmaj hall ., Text xxbos xxmaj in 2006 , xxunk starred alongside xxunk in the play xxunk written by xxmaj mark xxunk . xxmaj he appeared on a 2006 episode of the television series , xxmaj doctors , followed by a role in the 2007 theatre production of xxmaj how to xxmaj curse directed by xxunk xxunk . xxmaj how to xxmaj curse was performed at xxmaj bush xxmaj theatre in the xxmaj london xxmaj borough of xxunk and xxmaj fulham . xxunk starred in two films in 2008 , xxunk xxunk by filmmaker xxmaj paris xxunk , and xxunk xxmaj punch directed by xxunk xxmaj blackburn . xxmaj in xxmaj may 2008 , xxunk made a guest appearance on a two - part episode arc of the television series xxmaj waking the xxmaj dead , followed by an appearance on the television series xxunk in xxmaj november 2008 . xxmaj he had a recurring role in ten episodes of the television series xxunk in 2010 , as \" xxunk xxmaj fletcher \" . xxunk starred in the 2011 film xxunk directed by xxmaj paris xxunk ., Text xxbos = = xxmaj career = =, Text xxbos = = = 2000 – 2005 = = =]...\n",
      "Path: data/wikitext-2, model=Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (dropout_emb): Dropout(p=0.1)\n",
      "    (src_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (tgt_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tgt_word_prj): Linear(in_features=512, out_features=29172, bias=False)\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f7a78dd9780>, metrics=[<function accuracy at 0x7f79d2677620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data/wikitext-2'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[TransformerTrainer\n",
      "learn: LanguageLearner(data=TextLMDataBunch;\n",
      "\n",
      "Train: LabelList\n",
      "y: LMLabel (23767 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (23767 items)\n",
      "[Text xxbos = xxmaj valkyria xxmaj chronicles xxup iii =, Text xxbos xxmaj senjō no xxmaj valkyria 3 : xxunk xxmaj chronicles ( xxmaj japanese : 戦場のヴァルキュリア3 , lit . xxmaj valkyria of the xxmaj battlefield 3 ) , commonly referred to as xxmaj valkyria xxmaj chronicles xxup iii outside xxmaj japan , is a tactical role - playing video game developed by xxmaj sega and xxmaj media . xxmaj vision for the playstation xxmaj portable . xxmaj released in xxmaj january 2011 in xxmaj japan , it is the third game in the xxmaj valkyria series . xxunk the same fusion of tactical and real - time gameplay as its predecessors , the story runs parallel to the first game and follows the \" xxmaj nameless \" , a penal military unit serving the nation of xxmaj gallia during the xxmaj second xxmaj europan xxmaj war who perform secret black operations and are pitted against the xxmaj imperial unit \" xxunk xxmaj raven \" ., Text xxbos xxmaj the game began development in 2010 , carrying over a large portion of the work done on xxmaj valkyria xxmaj chronicles xxup ii . xxmaj while it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more xxunk for series newcomers . xxmaj character designer xxunk xxmaj honjou and composer xxmaj hitoshi xxmaj sakimoto both returned from previous entries , along with xxmaj valkyria xxmaj chronicles xxup ii director xxmaj takeshi xxmaj ozawa . a large team of writers handled the script . xxmaj the game 's opening theme was sung by xxmaj may ' n ., Text xxbos xxmaj it met with positive sales in xxmaj japan , and was praised by both xxmaj japanese and western critics . xxmaj after release , it received downloadable content , along with an expanded edition in xxmaj november of that year . xxmaj it was also adapted into manga and an original video animation series . xxmaj due to low sales of xxmaj valkyria xxmaj chronicles xxup ii , xxmaj valkyria xxmaj chronicles xxup iii was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . xxmaj media . xxmaj vision would return to the franchise with the development of xxmaj valkyria : xxmaj azure xxmaj revolution for the playstation 4 ., Text xxbos = = xxmaj gameplay = =]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Valid: LabelList\n",
      "y: LMLabel (2461 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2461 items)\n",
      "[Text xxbos = xxmaj homarus gammarus =, Text xxbos xxmaj homarus gammarus , known as the xxmaj european lobster or common lobster , is a species of xxunk lobster from the eastern xxmaj atlantic xxmaj ocean , xxmaj mediterranean xxmaj sea and parts of the xxmaj black xxmaj sea . xxmaj it is closely related to the xxmaj american lobster , xxup h. americanus . xxmaj it may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . xxmaj in life , the lobsters are blue , only becoming \" lobster red \" on cooking . xxmaj mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into xxunk larvae . xxmaj homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the xxmaj british xxmaj isles ., Text xxbos = = xxmaj description = =, Text xxbos xxmaj homarus gammarus is a large xxunk , with a body length up to 60 centimetres ( 24 in ) and weighing up to 5 – 6 kilograms ( 11 – 13 lb ) , although the lobsters caught in lobster pots are usually 23 – 38 cm ( 9 – 15 in ) long and weigh 0.7 – 2.2 kg ( 1.5 – 4.9 lb ) . xxmaj like other crustaceans , lobsters have a hard xxunk which they must shed in order to grow , in a process called xxunk ( xxunk ) . xxmaj this may occur several times a year for young lobsters , but decreases to once every 1 – 2 years for larger animals ., Text xxbos xxmaj the first pair of xxunk is armed with a large , asymmetrical pair of claws . xxmaj the larger one is the \" xxunk \" , and has rounded xxunk used for crushing prey ; the other is the \" cutter \" , which has sharp inner edges , and is used for holding or tearing the prey . xxmaj usually , the left claw is the xxunk , and the right is the cutter .]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Test: LabelList\n",
      "y: LMLabel (2891 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2891 items)\n",
      "[Text xxbos = xxmaj robert xxunk =, Text xxbos xxmaj robert xxunk is an xxmaj english film , television and theatre actor . xxmaj he had a guest - starring role on the television series xxmaj the xxmaj bill in 2000 . xxmaj this was followed by a starring role in the play xxmaj herons written by xxmaj simon xxmaj stephens , which was performed in 2001 at the xxmaj royal xxmaj court xxmaj theatre . xxmaj he had a guest role in the television series xxmaj judge xxmaj john xxunk in 2002 . xxmaj in 2004 xxunk landed a role as \" xxmaj craig \" in the episode \" xxmaj teddy 's xxmaj story \" of the television series xxmaj the xxmaj long xxmaj firm ; he starred alongside actors xxmaj mark xxmaj strong and xxmaj derek xxmaj jacobi . xxmaj he was cast in the 2005 theatre productions of the xxmaj philip xxmaj ridley play xxmaj mercury xxmaj fur , which was performed at the xxmaj drum xxmaj theatre in xxmaj plymouth and the xxunk xxunk xxmaj factory in xxmaj london . xxmaj he was directed by xxmaj john xxunk and starred alongside xxmaj ben xxunk , xxmaj shane xxunk , xxmaj harry xxmaj kent , xxmaj fraser xxunk , xxmaj sophie xxmaj stanton and xxmaj dominic xxmaj hall ., Text xxbos xxmaj in 2006 , xxunk starred alongside xxunk in the play xxunk written by xxmaj mark xxunk . xxmaj he appeared on a 2006 episode of the television series , xxmaj doctors , followed by a role in the 2007 theatre production of xxmaj how to xxmaj curse directed by xxunk xxunk . xxmaj how to xxmaj curse was performed at xxmaj bush xxmaj theatre in the xxmaj london xxmaj borough of xxunk and xxmaj fulham . xxunk starred in two films in 2008 , xxunk xxunk by filmmaker xxmaj paris xxunk , and xxunk xxmaj punch directed by xxunk xxmaj blackburn . xxmaj in xxmaj may 2008 , xxunk made a guest appearance on a two - part episode arc of the television series xxmaj waking the xxmaj dead , followed by an appearance on the television series xxunk in xxmaj november 2008 . xxmaj he had a recurring role in ten episodes of the television series xxunk in 2010 , as \" xxunk xxmaj fletcher \" . xxunk starred in the 2011 film xxunk directed by xxmaj paris xxunk ., Text xxbos = = xxmaj career = =, Text xxbos = = = 2000 – 2005 = = =]...\n",
      "Path: data/wikitext-2, model=Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (dropout_emb): Dropout(p=0.1)\n",
      "    (src_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (tgt_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tgt_word_prj): Linear(in_features=512, out_features=29172, bias=False)\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f7a78dd9780>, metrics=[<function accuracy at 0x7f79d2677620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data/wikitext-2'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
      "  (0): Dropout(p=0.1)\n",
      "  (1): Embedding(29172, 512, padding_idx=1)\n",
      "  (2): Embedding(154, 512)\n",
      "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Softmax()\n",
      "  (8): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (9): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "  (11): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (12): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (13): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (14): Dropout(p=0.1)\n",
      "  (15): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (17): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (18): Dropout(p=0.1)\n",
      "  (19): Softmax()\n",
      "  (20): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (21): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (22): Dropout(p=0.1)\n",
      "  (23): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (24): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (25): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (26): Dropout(p=0.1)\n",
      "  (27): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (28): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (29): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (30): Dropout(p=0.1)\n",
      "  (31): Softmax()\n",
      "  (32): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (33): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (34): Dropout(p=0.1)\n",
      "  (35): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (36): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (37): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (38): Dropout(p=0.1)\n",
      "  (39): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (40): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (41): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (42): Dropout(p=0.1)\n",
      "  (43): Softmax()\n",
      "  (44): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (45): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (46): Dropout(p=0.1)\n",
      "  (47): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (48): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (49): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (50): Dropout(p=0.1)\n",
      "  (51): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (52): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (53): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (54): Dropout(p=0.1)\n",
      "  (55): Softmax()\n",
      "  (56): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (57): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (58): Dropout(p=0.1)\n",
      "  (59): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (60): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (61): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (62): Dropout(p=0.1)\n",
      "  (63): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (64): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (65): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (66): Dropout(p=0.1)\n",
      "  (67): Softmax()\n",
      "  (68): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (69): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (70): Dropout(p=0.1)\n",
      "  (71): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (72): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (73): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (74): Dropout(p=0.1)\n",
      "  (75): Embedding(29172, 512, padding_idx=1)\n",
      "  (76): Embedding(154, 512)\n",
      "  (77): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (78): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (79): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (80): Dropout(p=0.1)\n",
      "  (81): Softmax()\n",
      "  (82): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (83): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (84): Dropout(p=0.1)\n",
      "  (85): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (86): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (87): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (88): Dropout(p=0.1)\n",
      "  (89): Softmax()\n",
      "  (90): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (91): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (92): Dropout(p=0.1)\n",
      "  (93): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (94): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (95): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (96): Dropout(p=0.1)\n",
      "  (97): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (98): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (99): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (100): Dropout(p=0.1)\n",
      "  (101): Softmax()\n",
      "  (102): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (103): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (104): Dropout(p=0.1)\n",
      "  (105): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (106): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (107): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (108): Dropout(p=0.1)\n",
      "  (109): Softmax()\n",
      "  (110): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (111): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (112): Dropout(p=0.1)\n",
      "  (113): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (114): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (115): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (116): Dropout(p=0.1)\n",
      "  (117): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (118): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (119): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (120): Dropout(p=0.1)\n",
      "  (121): Softmax()\n",
      "  (122): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (123): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (124): Dropout(p=0.1)\n",
      "  (125): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (126): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (127): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (128): Dropout(p=0.1)\n",
      "  (129): Softmax()\n",
      "  (130): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (131): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (132): Dropout(p=0.1)\n",
      "  (133): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (134): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (135): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (136): Dropout(p=0.1)\n",
      "  (137): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (138): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (139): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (140): Dropout(p=0.1)\n",
      "  (141): Softmax()\n",
      "  (142): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (143): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (144): Dropout(p=0.1)\n",
      "  (145): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (146): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (147): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (148): Dropout(p=0.1)\n",
      "  (149): Softmax()\n",
      "  (150): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (151): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (152): Dropout(p=0.1)\n",
      "  (153): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (154): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (155): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (156): Dropout(p=0.1)\n",
      "  (157): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (158): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (159): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (160): Dropout(p=0.1)\n",
      "  (161): Softmax()\n",
      "  (162): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (163): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (164): Dropout(p=0.1)\n",
      "  (165): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (166): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (167): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (168): Dropout(p=0.1)\n",
      "  (169): Softmax()\n",
      "  (170): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (171): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (172): Dropout(p=0.1)\n",
      "  (173): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (174): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (175): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (176): Dropout(p=0.1)\n",
      "  (177): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (178): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (179): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (180): Dropout(p=0.1)\n",
      "  (181): Softmax()\n",
      "  (182): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (183): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (184): Dropout(p=0.1)\n",
      "  (185): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (186): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (187): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (188): Dropout(p=0.1)\n",
      "  (189): Softmax()\n",
      "  (190): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (191): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (192): Dropout(p=0.1)\n",
      "  (193): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (194): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (195): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (196): Dropout(p=0.1)\n",
      "  (197): Linear(in_features=512, out_features=29172, bias=False)\n",
      ")])\n",
      "bptt: 128\n",
      "adjust: False, MixedPrecision\n",
      "learn: LanguageLearner(data=TextLMDataBunch;\n",
      "\n",
      "Train: LabelList\n",
      "y: LMLabel (23767 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (23767 items)\n",
      "[Text xxbos = xxmaj valkyria xxmaj chronicles xxup iii =, Text xxbos xxmaj senjō no xxmaj valkyria 3 : xxunk xxmaj chronicles ( xxmaj japanese : 戦場のヴァルキュリア3 , lit . xxmaj valkyria of the xxmaj battlefield 3 ) , commonly referred to as xxmaj valkyria xxmaj chronicles xxup iii outside xxmaj japan , is a tactical role - playing video game developed by xxmaj sega and xxmaj media . xxmaj vision for the playstation xxmaj portable . xxmaj released in xxmaj january 2011 in xxmaj japan , it is the third game in the xxmaj valkyria series . xxunk the same fusion of tactical and real - time gameplay as its predecessors , the story runs parallel to the first game and follows the \" xxmaj nameless \" , a penal military unit serving the nation of xxmaj gallia during the xxmaj second xxmaj europan xxmaj war who perform secret black operations and are pitted against the xxmaj imperial unit \" xxunk xxmaj raven \" ., Text xxbos xxmaj the game began development in 2010 , carrying over a large portion of the work done on xxmaj valkyria xxmaj chronicles xxup ii . xxmaj while it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more xxunk for series newcomers . xxmaj character designer xxunk xxmaj honjou and composer xxmaj hitoshi xxmaj sakimoto both returned from previous entries , along with xxmaj valkyria xxmaj chronicles xxup ii director xxmaj takeshi xxmaj ozawa . a large team of writers handled the script . xxmaj the game 's opening theme was sung by xxmaj may ' n ., Text xxbos xxmaj it met with positive sales in xxmaj japan , and was praised by both xxmaj japanese and western critics . xxmaj after release , it received downloadable content , along with an expanded edition in xxmaj november of that year . xxmaj it was also adapted into manga and an original video animation series . xxmaj due to low sales of xxmaj valkyria xxmaj chronicles xxup ii , xxmaj valkyria xxmaj chronicles xxup iii was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . xxmaj media . xxmaj vision would return to the franchise with the development of xxmaj valkyria : xxmaj azure xxmaj revolution for the playstation 4 ., Text xxbos = = xxmaj gameplay = =]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Valid: LabelList\n",
      "y: LMLabel (2461 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2461 items)\n",
      "[Text xxbos = xxmaj homarus gammarus =, Text xxbos xxmaj homarus gammarus , known as the xxmaj european lobster or common lobster , is a species of xxunk lobster from the eastern xxmaj atlantic xxmaj ocean , xxmaj mediterranean xxmaj sea and parts of the xxmaj black xxmaj sea . xxmaj it is closely related to the xxmaj american lobster , xxup h. americanus . xxmaj it may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . xxmaj in life , the lobsters are blue , only becoming \" lobster red \" on cooking . xxmaj mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into xxunk larvae . xxmaj homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the xxmaj british xxmaj isles ., Text xxbos = = xxmaj description = =, Text xxbos xxmaj homarus gammarus is a large xxunk , with a body length up to 60 centimetres ( 24 in ) and weighing up to 5 – 6 kilograms ( 11 – 13 lb ) , although the lobsters caught in lobster pots are usually 23 – 38 cm ( 9 – 15 in ) long and weigh 0.7 – 2.2 kg ( 1.5 – 4.9 lb ) . xxmaj like other crustaceans , lobsters have a hard xxunk which they must shed in order to grow , in a process called xxunk ( xxunk ) . xxmaj this may occur several times a year for young lobsters , but decreases to once every 1 – 2 years for larger animals ., Text xxbos xxmaj the first pair of xxunk is armed with a large , asymmetrical pair of claws . xxmaj the larger one is the \" xxunk \" , and has rounded xxunk used for crushing prey ; the other is the \" cutter \" , which has sharp inner edges , and is used for holding or tearing the prey . xxmaj usually , the left claw is the xxunk , and the right is the cutter .]...\n",
      "Path: data/wikitext-2;\n",
      "\n",
      "Test: LabelList\n",
      "y: LMLabel (2891 items)\n",
      "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
      "Path: data/wikitext-2\n",
      "x: LMTextList (2891 items)\n",
      "[Text xxbos = xxmaj robert xxunk =, Text xxbos xxmaj robert xxunk is an xxmaj english film , television and theatre actor . xxmaj he had a guest - starring role on the television series xxmaj the xxmaj bill in 2000 . xxmaj this was followed by a starring role in the play xxmaj herons written by xxmaj simon xxmaj stephens , which was performed in 2001 at the xxmaj royal xxmaj court xxmaj theatre . xxmaj he had a guest role in the television series xxmaj judge xxmaj john xxunk in 2002 . xxmaj in 2004 xxunk landed a role as \" xxmaj craig \" in the episode \" xxmaj teddy 's xxmaj story \" of the television series xxmaj the xxmaj long xxmaj firm ; he starred alongside actors xxmaj mark xxmaj strong and xxmaj derek xxmaj jacobi . xxmaj he was cast in the 2005 theatre productions of the xxmaj philip xxmaj ridley play xxmaj mercury xxmaj fur , which was performed at the xxmaj drum xxmaj theatre in xxmaj plymouth and the xxunk xxunk xxmaj factory in xxmaj london . xxmaj he was directed by xxmaj john xxunk and starred alongside xxmaj ben xxunk , xxmaj shane xxunk , xxmaj harry xxmaj kent , xxmaj fraser xxunk , xxmaj sophie xxmaj stanton and xxmaj dominic xxmaj hall ., Text xxbos xxmaj in 2006 , xxunk starred alongside xxunk in the play xxunk written by xxmaj mark xxunk . xxmaj he appeared on a 2006 episode of the television series , xxmaj doctors , followed by a role in the 2007 theatre production of xxmaj how to xxmaj curse directed by xxunk xxunk . xxmaj how to xxmaj curse was performed at xxmaj bush xxmaj theatre in the xxmaj london xxmaj borough of xxunk and xxmaj fulham . xxunk starred in two films in 2008 , xxunk xxunk by filmmaker xxmaj paris xxunk , and xxunk xxmaj punch directed by xxunk xxmaj blackburn . xxmaj in xxmaj may 2008 , xxunk made a guest appearance on a two - part episode arc of the television series xxmaj waking the xxmaj dead , followed by an appearance on the television series xxunk in xxmaj november 2008 . xxmaj he had a recurring role in ten episodes of the television series xxunk in 2010 , as \" xxunk xxmaj fletcher \" . xxunk starred in the 2011 film xxunk directed by xxmaj paris xxunk ., Text xxbos = = xxmaj career = =, Text xxbos = = = 2000 – 2005 = = =]...\n",
      "Path: data/wikitext-2, model=Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (dropout_emb): Dropout(p=0.1)\n",
      "    (src_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (tgt_word_emb): Embedding(29172, 512, padding_idx=1)\n",
      "    (position_enc): Embedding(154, 512)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (enc_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_ks): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_vs): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (dropout): Dropout(p=0.1)\n",
      "            (softmax): Softmax()\n",
      "          )\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (w_2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tgt_word_prj): Linear(in_features=512, out_features=29172, bias=False)\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f7a78dd9780>, metrics=[<function accuracy at 0x7f79d2677620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data/wikitext-2'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
      "  (0): Dropout(p=0.1)\n",
      "  (1): Embedding(29172, 512, padding_idx=1)\n",
      "  (2): Embedding(154, 512)\n",
      "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Softmax()\n",
      "  (8): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (9): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "  (11): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (12): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (13): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (14): Dropout(p=0.1)\n",
      "  (15): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (17): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (18): Dropout(p=0.1)\n",
      "  (19): Softmax()\n",
      "  (20): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (21): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (22): Dropout(p=0.1)\n",
      "  (23): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (24): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (25): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (26): Dropout(p=0.1)\n",
      "  (27): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (28): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (29): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (30): Dropout(p=0.1)\n",
      "  (31): Softmax()\n",
      "  (32): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (33): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (34): Dropout(p=0.1)\n",
      "  (35): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (36): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (37): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (38): Dropout(p=0.1)\n",
      "  (39): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (40): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (41): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (42): Dropout(p=0.1)\n",
      "  (43): Softmax()\n",
      "  (44): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (45): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (46): Dropout(p=0.1)\n",
      "  (47): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (48): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (49): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (50): Dropout(p=0.1)\n",
      "  (51): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (52): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (53): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (54): Dropout(p=0.1)\n",
      "  (55): Softmax()\n",
      "  (56): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (57): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (58): Dropout(p=0.1)\n",
      "  (59): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (60): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (61): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (62): Dropout(p=0.1)\n",
      "  (63): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (64): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (65): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (66): Dropout(p=0.1)\n",
      "  (67): Softmax()\n",
      "  (68): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (69): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (70): Dropout(p=0.1)\n",
      "  (71): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (72): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (73): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (74): Dropout(p=0.1)\n",
      "  (75): Embedding(29172, 512, padding_idx=1)\n",
      "  (76): Embedding(154, 512)\n",
      "  (77): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (78): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (79): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (80): Dropout(p=0.1)\n",
      "  (81): Softmax()\n",
      "  (82): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (83): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (84): Dropout(p=0.1)\n",
      "  (85): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (86): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (87): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (88): Dropout(p=0.1)\n",
      "  (89): Softmax()\n",
      "  (90): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (91): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (92): Dropout(p=0.1)\n",
      "  (93): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (94): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (95): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (96): Dropout(p=0.1)\n",
      "  (97): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (98): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (99): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (100): Dropout(p=0.1)\n",
      "  (101): Softmax()\n",
      "  (102): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (103): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (104): Dropout(p=0.1)\n",
      "  (105): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (106): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (107): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (108): Dropout(p=0.1)\n",
      "  (109): Softmax()\n",
      "  (110): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (111): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (112): Dropout(p=0.1)\n",
      "  (113): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (114): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (115): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (116): Dropout(p=0.1)\n",
      "  (117): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (118): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (119): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (120): Dropout(p=0.1)\n",
      "  (121): Softmax()\n",
      "  (122): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (123): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (124): Dropout(p=0.1)\n",
      "  (125): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (126): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (127): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (128): Dropout(p=0.1)\n",
      "  (129): Softmax()\n",
      "  (130): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (131): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (132): Dropout(p=0.1)\n",
      "  (133): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (134): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (135): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (136): Dropout(p=0.1)\n",
      "  (137): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (138): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (139): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (140): Dropout(p=0.1)\n",
      "  (141): Softmax()\n",
      "  (142): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (143): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (144): Dropout(p=0.1)\n",
      "  (145): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (146): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (147): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (148): Dropout(p=0.1)\n",
      "  (149): Softmax()\n",
      "  (150): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (151): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (152): Dropout(p=0.1)\n",
      "  (153): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (154): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (155): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (156): Dropout(p=0.1)\n",
      "  (157): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (158): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (159): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (160): Dropout(p=0.1)\n",
      "  (161): Softmax()\n",
      "  (162): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (163): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (164): Dropout(p=0.1)\n",
      "  (165): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (166): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (167): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (168): Dropout(p=0.1)\n",
      "  (169): Softmax()\n",
      "  (170): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (171): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (172): Dropout(p=0.1)\n",
      "  (173): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (174): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (175): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (176): Dropout(p=0.1)\n",
      "  (177): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (178): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (179): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (180): Dropout(p=0.1)\n",
      "  (181): Softmax()\n",
      "  (182): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (183): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (184): Dropout(p=0.1)\n",
      "  (185): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (186): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (187): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (188): Dropout(p=0.1)\n",
      "  (189): Softmax()\n",
      "  (190): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (191): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (192): Dropout(p=0.1)\n",
      "  (193): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (194): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (195): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (196): Dropout(p=0.1)\n",
      "  (197): Linear(in_features=512, out_features=29172, bias=False)\n",
      ")])\n",
      "loss_scale: 256\n",
      "flat_master: False], layer_groups=[Sequential(\n",
      "  (0): Dropout(p=0.1)\n",
      "  (1): Embedding(29172, 512, padding_idx=1)\n",
      "  (2): Embedding(154, 512)\n",
      "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (6): Dropout(p=0.1)\n",
      "  (7): Softmax()\n",
      "  (8): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (9): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (10): Dropout(p=0.1)\n",
      "  (11): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (12): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (13): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (14): Dropout(p=0.1)\n",
      "  (15): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (17): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (18): Dropout(p=0.1)\n",
      "  (19): Softmax()\n",
      "  (20): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (21): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (22): Dropout(p=0.1)\n",
      "  (23): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (24): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (25): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (26): Dropout(p=0.1)\n",
      "  (27): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (28): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (29): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (30): Dropout(p=0.1)\n",
      "  (31): Softmax()\n",
      "  (32): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (33): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (34): Dropout(p=0.1)\n",
      "  (35): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (36): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (37): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (38): Dropout(p=0.1)\n",
      "  (39): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (40): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (41): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (42): Dropout(p=0.1)\n",
      "  (43): Softmax()\n",
      "  (44): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (45): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (46): Dropout(p=0.1)\n",
      "  (47): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (48): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (49): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (50): Dropout(p=0.1)\n",
      "  (51): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (52): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (53): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (54): Dropout(p=0.1)\n",
      "  (55): Softmax()\n",
      "  (56): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (57): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (58): Dropout(p=0.1)\n",
      "  (59): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (60): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (61): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (62): Dropout(p=0.1)\n",
      "  (63): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (64): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (65): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (66): Dropout(p=0.1)\n",
      "  (67): Softmax()\n",
      "  (68): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (69): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (70): Dropout(p=0.1)\n",
      "  (71): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (72): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (73): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (74): Dropout(p=0.1)\n",
      "  (75): Embedding(29172, 512, padding_idx=1)\n",
      "  (76): Embedding(154, 512)\n",
      "  (77): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (78): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (79): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (80): Dropout(p=0.1)\n",
      "  (81): Softmax()\n",
      "  (82): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (83): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (84): Dropout(p=0.1)\n",
      "  (85): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (86): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (87): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (88): Dropout(p=0.1)\n",
      "  (89): Softmax()\n",
      "  (90): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (91): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (92): Dropout(p=0.1)\n",
      "  (93): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (94): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (95): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (96): Dropout(p=0.1)\n",
      "  (97): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (98): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (99): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (100): Dropout(p=0.1)\n",
      "  (101): Softmax()\n",
      "  (102): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (103): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (104): Dropout(p=0.1)\n",
      "  (105): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (106): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (107): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (108): Dropout(p=0.1)\n",
      "  (109): Softmax()\n",
      "  (110): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (111): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (112): Dropout(p=0.1)\n",
      "  (113): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (114): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (115): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (116): Dropout(p=0.1)\n",
      "  (117): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (118): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (119): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (120): Dropout(p=0.1)\n",
      "  (121): Softmax()\n",
      "  (122): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (123): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (124): Dropout(p=0.1)\n",
      "  (125): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (126): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (127): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (128): Dropout(p=0.1)\n",
      "  (129): Softmax()\n",
      "  (130): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (131): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (132): Dropout(p=0.1)\n",
      "  (133): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (134): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (135): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (136): Dropout(p=0.1)\n",
      "  (137): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (138): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (139): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (140): Dropout(p=0.1)\n",
      "  (141): Softmax()\n",
      "  (142): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (143): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (144): Dropout(p=0.1)\n",
      "  (145): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (146): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (147): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (148): Dropout(p=0.1)\n",
      "  (149): Softmax()\n",
      "  (150): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (151): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (152): Dropout(p=0.1)\n",
      "  (153): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (154): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (155): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (156): Dropout(p=0.1)\n",
      "  (157): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (158): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (159): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (160): Dropout(p=0.1)\n",
      "  (161): Softmax()\n",
      "  (162): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (163): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (164): Dropout(p=0.1)\n",
      "  (165): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (166): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (167): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (168): Dropout(p=0.1)\n",
      "  (169): Softmax()\n",
      "  (170): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (171): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (172): Dropout(p=0.1)\n",
      "  (173): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (174): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (175): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (176): Dropout(p=0.1)\n",
      "  (177): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (178): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (179): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (180): Dropout(p=0.1)\n",
      "  (181): Softmax()\n",
      "  (182): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (183): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (184): Dropout(p=0.1)\n",
      "  (185): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (186): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (187): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (188): Dropout(p=0.1)\n",
      "  (189): Softmax()\n",
      "  (190): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (191): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (192): Dropout(p=0.1)\n",
      "  (193): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "  (194): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "  (195): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "  (196): Dropout(p=0.1)\n",
      "  (197): Linear(in_features=512, out_features=29172, bias=False)\n",
      ")])\n",
      "loss_scale: 256\n",
      "flat_master: False], metrics=[], beta=0.98)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.one_item('hello there, how are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 14:31 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>6.458280</th>\n",
       "    <th>6.267672</th>\n",
       "    <th>0.116723</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>6.504977</th>\n",
       "    <th>6.307535</th>\n",
       "    <th>0.116736</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>6.481110</th>\n",
       "    <th>6.299407</th>\n",
       "    <th>0.116903</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>6.483870</th>\n",
       "    <th>6.304560</th>\n",
       "    <th>0.116813</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>6.471123</th>\n",
       "    <th>6.296405</th>\n",
       "    <th>0.117554</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>6.473608</th>\n",
       "    <th>6.291907</th>\n",
       "    <th>0.116822</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>6.477888</th>\n",
       "    <th>6.290092</th>\n",
       "    <th>0.116859</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>6.471915</th>\n",
       "    <th>6.296666</th>\n",
       "    <th>0.116697</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>6.477241</th>\n",
       "    <th>6.288358</th>\n",
       "    <th>0.116972</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>6.464836</th>\n",
       "    <th>6.289388</th>\n",
       "    <th>0.117070</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find(num_it=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:17 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>6.460091</th>\n",
       "    <th>6.281972</th>\n",
       "    <th>0.116671</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-1, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:25 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>6.487091</th>\n",
       "    <th>6.282309</th>\n",
       "    <th>0.116063</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>6.448372</th>\n",
       "    <th>6.262347</th>\n",
       "    <th>0.117127</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-3, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='12', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/12 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='579', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3f9ec6873bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     21\u001b[0m                                         pct_start=pct_start, **kwargs))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 173\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/callback.py\u001b[0m in \u001b[0;36mon_backward_begin\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;34m\"Handle gradient calculation on `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smooth_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(12, 1e-3, moms=(0.7,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('transformer_run1_1en4');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
