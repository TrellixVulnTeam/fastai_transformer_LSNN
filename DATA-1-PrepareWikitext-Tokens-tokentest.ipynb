{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from fastai import *        # Quick accesss to most common functionality\n",
    "from fastai.text import *   # Quick accesss to NLP functionality\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xxunk', 0),\n",
       " ('xxpad', 1),\n",
       " ('xxbos', 2),\n",
       " ('xxfld', 3),\n",
       " ('xxmaj', 4),\n",
       " ('xxup', 5),\n",
       " ('xxrep', 6),\n",
       " ('xxwrep', 7)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(s,v.stoi[s]) for s in tst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/wikitext-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_url('https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip', PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fn:PathOrStr, enc='utf-8'):\n",
    "    \"Read the text in `fn`.\"\n",
    "#     with open(fn,'r', encoding = enc) as f: return ''.join(f.read().splitlines())\n",
    "    tokens = []\n",
    "    with open(fn,'r', encoding = enc) as f: \n",
    "        for line in f.read().splitlines():\n",
    "            l = line.strip()\n",
    "            if len(l) == 0: continue\n",
    "            tokens.append(l)#.split())\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = read_file(PATH/'wiki.train.tokens')\n",
    "valid_tok = read_file(PATH/'wiki.valid.tokens')\n",
    "test_tok = read_file(PATH/'wiki.test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprer = defaults.text_pre_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpostr = defaults.text_post_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = defaults.text_spec_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_html(x:str) -> str:\n",
    "    \"List of replacements from html strings in `x`.\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "#         'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "#         '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "#     return x\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_html(x:str) -> str:\n",
    "    \"List of replacements from html strings in `x`.\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace(#'#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "#         'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "#         '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-')#.replace('\\\\', ' \\\\ ')\n",
    "#     return x\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_html(x:str) -> str:\n",
    "    \"List of replacements from html strings in `x`.\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "#         'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "#         '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-')#.replace('\\\\', ' \\\\ ')\n",
    "#     return x\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_html(x:str) -> str:\n",
    "    \"List of replacements from html strings in `x`.\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "#         'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "#         '<br />', \"\\n\").replace('\\\\\"', '\"').replace(\n",
    "        '<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-')#.replace('\\\\', ' \\\\ ')\n",
    "#     return x\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_html(x:str) -> str:\n",
    "    \"List of replacements from html strings in `x`.\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace(#'#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "#         'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "#         '<br />', \"\\n\").replace('\\\\\"', '\"').replace(\n",
    "#         '<unk>',UNK).replace(#' @.@ ','.').replace(\n",
    "        ' @-@ ','-')#.replace('\\\\', ' \\\\ ')\n",
    "#     return x\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "# replacing unk fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_2 = ['xxunkxx'] + tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunkxx',\n",
       " 'xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_html(x:str) -> str:\n",
    "    return x.replace('<unk>', 'xxunkxx')\n",
    "\n",
    "# replacing unk fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fix_html(x:str) -> str:\n",
    "#     \"List of replacements from html strings in `x`.\"\n",
    "#     re1 = re.compile(r'  +')\n",
    "#     x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "#         'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "#         '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "#         ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "# #     return x\n",
    "#     return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dsfdsdjfkldss xxunkxx'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_html('dsfdsdjfkldss <unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprer = [fix_html] + tprer[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(pre_rules=tprer, post_rules=tpostr, special_cases=tst_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok.pre_rules  = []\n",
    "# tok.post_rules = []\n",
    "# tok.special_cases = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = data._get_processor(tokenizer=tok, vocab=None, max_vocab=10)\n",
    "src = ItemLists(path, TextList(train_tok, path=path, processor=processor),\n",
    "                TextList(valid_tok, path=path, processor=processor))\n",
    "src = src.label_for_lm()\n",
    "if test_tok is not None: src.add_test(TextList(test_tok, path=path))\n",
    "db = src.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save('tmp_tok_28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 95]) tensor(16, device='cuda:0') tensor(3.3507, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 95]) tensor(16, device='cuda:0') tensor(3.3260, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 70]) tensor(16, device='cuda:0') tensor(3.2942, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 70]) tensor(16, device='cuda:0') tensor(3.2964, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 71]) tensor(16, device='cuda:0') tensor(3.2044, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 71]) tensor(16, device='cuda:0') tensor(3.2053, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 77]) tensor(16, device='cuda:0') tensor(3.3164, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 77]) tensor(16, device='cuda:0') tensor(3.3202, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 71]) tensor(16, device='cuda:0') tensor(3.4140, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 71]) tensor(16, device='cuda:0') tensor(3.4151, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 64]) tensor(16, device='cuda:0') tensor(3.2532, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 64]) tensor(16, device='cuda:0') tensor(3.2617, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 77]) tensor(16, device='cuda:0') tensor(3.3017, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 77]) tensor(16, device='cuda:0') tensor(3.2881, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 40]) tensor(16, device='cuda:0') tensor(3.2977, device='cuda:0') torch.cuda.LongTensor\n",
      "torch.Size([64, 40]) tensor(16, device='cuda:0') tensor(3.2938, device='cuda:0') torch.cuda.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(db.train_dl):\n",
    "    print(x.shape, x.max(), x.float().mean(), x.type())\n",
    "    print(y.shape, y.max(), y.float().mean(), y.type())\n",
    "    if i > 6: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = db.train_ds.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi['xxunkxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-6eed0a09f19c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-6eed0a09f19c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    db.train_ds.vocab.\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "db.train_ds.vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29060)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   2,    4,    8,  ..., 4780,    9,   38],\n",
       "         [   4, 1001,    4,  ...,   26,    4, 3050],\n",
       "         [ 199,  300,    9,  ...,   86,    9,   19],\n",
       "         ...,\n",
       "         [   4,   44,   19,  ...,   15,  458,   13],\n",
       "         [2847,  557,  205,  ...,   28,   12, 2076],\n",
       "         [   4,    8,  566,  ...,    4,  679,  141]]),\n",
       " tensor([[    4,     8,  6936,  ...,     9,    38,  1391],\n",
       "         [ 1001,     4,   229,  ...,     4,  3050,    20],\n",
       "         [  300,     9,   358,  ...,     9,    19,    12],\n",
       "         ...,\n",
       "         [   44,    19,     8,  ...,   458,    13,     0],\n",
       "         [  557,   205,  7993,  ...,    12,  2076, 15853],\n",
       "         [    8,   566,   549,  ...,   679,   141,     8]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob = db.one_batch(); ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='5%'>  <col width='95%'>  <tr>\n",
       "    <th>idx</th>\n",
       "    <th>text</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>xxbos xxunk xxunk xxunk xxmaj xxunk to xxmaj xxunk xxunk xxunk xxunk xxunk xxunk xxbos xxmaj xxunk xxunk xxunk xxunk xxunk , xxunk xxunk xxmaj xxunk xxmaj xxunk xxmaj xxunk xxunk xxunk to xxunk , xxunk xxunk xxunk xxunk xxunkxx xxunk xxmaj xxunk xxunkxx xxunk xxmaj xxunk xxunkxx , xxmaj xxunk . xxmaj xxunk and xxmaj xxunk xxunk in xxmaj xxunk xxunk xxmaj xxunk xxunk , xxunk and xxunk xxunk</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>xxmaj xxunk xxunk xxunk xxunk xxbos xxmaj the xxunk xxunk xxunk xxunk the xxunk of xxunk xxunk xxunk xxmaj xxunk and xxunk xxunk xxunk xxunk xxunk xxunkxx . xxmaj xxunk xxunk xxunk xxunk xxunk a xxunk xxunk , xxunk xxunk xxunk xxunk in xxmaj xxunk . xxmaj in xxmaj xxunk xxunk xxunk , xxunk xxunk xxunk of the xxunk xxunk xxunk xxunk xxunk xxunk to xxunk xxunk and xxunk xxunk</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>xxunk xxunk xxunk xxunk xxunk in the xxunk , xxunk xxunkxx xxunk in xxunk and xxunk xxunk xxunk xxunk xxunk to xxunk the xxunk xxunk . xxbos xxmaj the xxmaj xxunk xxunk xxunk xxunk in the xxunk of xxmaj xxunk xxunk in xxmaj xxunk xxunk xxunk xxunk of the xxunk xxunkxx xxunk xxunk xxunk . xxmaj xxunk , the xxunk of xxmaj xxunk xxunk xxunk xxunk xxunk xxmaj xxunk .</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>a xxunk to xxunk the xxunk xxunk xxunk , xxunk xxunk xxunk xxunk the xxunk xxunk xxunk the xxunk . xxmaj the xxunk xxunkxx xxunk to a xxmaj xxunk xxmaj xxunk xxunk xxunk xxmaj xxunk and xxmaj xxunk xxunk the xxunk . xxmaj xxunk xxmaj xxunk xxunk the xxunk , xxunk xxunk xxunk xxunk xxunk , xxunk the xxunk xxunk xxunk xxunk to xxunk . xxmaj the xxunk xxunk xxmaj</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>, xxunk xxmaj xxunk xxunk xxunk xxunk xxunk xxunk xxunk in xxunk . xxmaj xxunk xxunk xxmaj xxunk xxmaj xxunk xxunk xxunk xxunk xxunk xxmaj xxunk and xxmaj xxunk xxunk xxunk , the xxunk xxunk xxunk in the xxunk xxunk , and xxunk xxunk xxunk xxunk xxunk a xxunk xxunk xxunk . xxmaj xxunk xxmaj xxunk xxunk , xxunk , xxmaj xxunk xxunk xxunk to xxunk the xxunk , xxunk</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1165029, 2461, 2891)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tok), len(valid_tok), len(test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['=', 'Valkyria', 'Chronicles', 'III', '=']),\n",
       "       list(['Senjō', 'no', 'Valkyria', '3', ':', '<unk>', 'Chronicles', '(', 'Japanese', ':', '戦場のヴァルキュリア3', ',', 'lit', '.', 'Valkyria', 'of', 'the', 'Battlefield', '3', ')', ',', 'commonly', 'referred', 'to', 'as', 'Valkyria', 'Chronicles', 'III', 'outside', 'Japan', ',', 'is', 'a', 'tactical', 'role', '@-@', 'playing', 'video', 'game', 'developed', 'by', 'Sega', 'and', 'Media.Vision', 'for', 'the', 'PlayStation', 'Portable', '.', 'Released', 'in', 'January', '2011', 'in', 'Japan', ',', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'Valkyria', 'series', '.', 'Employing', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', '@-@', 'time', 'gameplay', 'as', 'its', 'predecessors', ',', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', '\"', 'Nameless', '\"', ',', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'Gallia', 'during', 'the', 'Second', 'Europan', 'War', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted', 'against', 'the', 'Imperial', 'unit', '\"', '<unk>', 'Raven', '\"', '.']),\n",
       "       list(['The', 'game', 'began', 'development', 'in', '2010', ',', 'carrying', 'over', 'a', 'large', 'portion', 'of', 'the', 'work', 'done', 'on', 'Valkyria', 'Chronicles', 'II', '.', 'While', 'it', 'retained', 'the', 'standard', 'features', 'of', 'the', 'series', ',', 'it', 'also', 'underwent', 'multiple', 'adjustments', ',', 'such', 'as', 'making', 'the', 'game', 'more', 'forgiving', 'for', 'series', 'newcomers', '.', 'Character', 'designer', '<unk>', 'Honjou', 'and', 'composer', 'Hitoshi', 'Sakimoto', 'both', 'returned', 'from', 'previous', 'entries', ',', 'along', 'with', 'Valkyria', 'Chronicles', 'II', 'director', 'Takeshi', 'Ozawa', '.', 'A', 'large', 'team', 'of', 'writers', 'handled', 'the', 'script', '.', 'The', 'game', \"'s\", 'opening', 'theme', 'was', 'sung', 'by', 'May', \"'n\", '.']),\n",
       "       list(['It', 'met', 'with', 'positive', 'sales', 'in', 'Japan', ',', 'and', 'was', 'praised', 'by', 'both', 'Japanese', 'and', 'western', 'critics', '.', 'After', 'release', ',', 'it', 'received', 'downloadable', 'content', ',', 'along', 'with', 'an', 'expanded', 'edition', 'in', 'November', 'of', 'that', 'year', '.', 'It', 'was', 'also', 'adapted', 'into', 'manga', 'and', 'an', 'original', 'video', 'animation', 'series', '.', 'Due', 'to', 'low', 'sales', 'of', 'Valkyria', 'Chronicles', 'II', ',', 'Valkyria', 'Chronicles', 'III', 'was', 'not', 'localized', ',', 'but', 'a', 'fan', 'translation', 'compatible', 'with', 'the', 'game', \"'s\", 'expanded', 'edition', 'was', 'released', 'in', '2014', '.', 'Media.Vision', 'would', 'return', 'to', 'the', 'franchise', 'with', 'the', 'development', 'of', 'Valkyria', ':', 'Azure', 'Revolution', 'for', 'the', 'PlayStation', '4', '.']),\n",
       "       list(['=', '=', 'Gameplay', '=', '='])], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tok[:5][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = TextLMDataBunch.from_tokens(\n",
    "    PATH, train_tok, valid_tok, test_tok, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = text_data.train_ds.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikitext-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/wikitext-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_url('https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip', PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = read_file(PATH/'wiki.train.tokens')\n",
    "valid_tok = read_file(PATH/'wiki.valid.tokens')\n",
    "test_tok = read_file(PATH/'wiki.test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36718, 3760, 4358)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tok), len(valid_tok), len(test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_tok[4][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = TextLMDataBunch.from_tokens(\n",
    "    PATH, train_tok, valid_tok, test_tok, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextLMDataBunch.load(PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
